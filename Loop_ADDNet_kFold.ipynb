{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db3b22ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from pytorch_metric_learning import losses\n",
    "from torchsummary import summary\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer, normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from scipy.stats import mode\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "from spikingjelly.activation_based import neuron, functional, surrogate, layer\n",
    "\n",
    "from einops import rearrange, repeat, einsum\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc8ede25-3f2c-44b4-a0ec-b1d93b5ef775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.csdn.net/cskywit/article/details/137448871\n",
    "# https://github.com/johnma2006/mamba-minimal/blob/master/model.py\n",
    "\n",
    "class MambaBlock(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        \"\"\"A single Mamba block, as described in Figure 3 in Section 3.4 in the Mamba paper [1].\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = input_channels\n",
    "        self.d_inner = self.d_model * 2\n",
    "        self.dt_rank = math.ceil(self.d_model / 16)\n",
    "        self.d_state = 16\n",
    "            \n",
    "        self.in_proj = nn.Linear(self.d_model, self.d_inner * 2)#, bias=args.bias)\n",
    "\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=self.d_inner,\n",
    "            out_channels=self.d_inner,\n",
    "            # bias=args.conv_bias,\n",
    "            kernel_size=3,\n",
    "            groups=self.d_inner,\n",
    "            padding=2,\n",
    "        )\n",
    "\n",
    "        # x_proj takes in `x` and outputs the input-specific Δ, B, C\n",
    "        self.x_proj = nn.Linear(self.d_inner, self.dt_rank + self.d_state * 2, bias=False)\n",
    "        \n",
    "        # dt_proj projects Δ from dt_rank to d_in\n",
    "        self.dt_proj = nn.Linear(self.dt_rank, self.d_inner, bias=True)\n",
    "\n",
    "        A = repeat(torch.arange(1, self.d_state + 1), 'n -> d n', d=self.d_inner)\n",
    "        self.A_log = nn.Parameter(torch.log(A))\n",
    "        self.D = nn.Parameter(torch.ones(self.d_inner))\n",
    "        self.out_proj = nn.Linear(self.d_inner, self.d_model) #, bias=args.bias)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Mamba block forward. This looks the same as Figure 3 in Section 3.4 in the Mamba paper [1].\n",
    "    \n",
    "        Args:\n",
    "            x: shape (b, l, d)    (See Glossary at top for definitions of b, l, d_in, n...)\n",
    "    \n",
    "        Returns:\n",
    "            output: shape (b, l, d)\n",
    "        \n",
    "        Official Implementation:\n",
    "            class Mamba, https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L119\n",
    "            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n",
    "            \n",
    "        \"\"\"\n",
    "        (b, l, d) = x.shape\n",
    "        \n",
    "        x_and_res = self.in_proj(x)  # shape (b, l, 2 * d_in)\n",
    "        (x, res) = x_and_res.split(split_size=[self.d_inner, self.d_inner], dim=-1)\n",
    "\n",
    "        x = rearrange(x, 'b l d_in -> b d_in l')\n",
    "        x = self.conv1d(x)[:, :, :l]\n",
    "        x = rearrange(x, 'b d_in l -> b l d_in')\n",
    "        \n",
    "        x = F.silu(x)\n",
    "\n",
    "        y = self.ssm(x)\n",
    "        \n",
    "        y = y * F.silu(res)\n",
    "        \n",
    "        output = self.out_proj(y)\n",
    "\n",
    "        return output\n",
    "\n",
    "    \n",
    "    def ssm(self, x):\n",
    "        \"\"\"Runs the SSM. See:\n",
    "            - Algorithm 2 in Section 3.2 in the Mamba paper [1]\n",
    "            - run_SSM(A, B, C, u) in The Annotated S4 [2]\n",
    "\n",
    "        Args:\n",
    "            x: shape (b, l, d_in)    (See Glossary at top for definitions of b, l, d_in, n...)\n",
    "    \n",
    "        Returns:\n",
    "            output: shape (b, l, d_in)\n",
    "\n",
    "        Official Implementation:\n",
    "            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n",
    "            \n",
    "        \"\"\"\n",
    "        (d_in, n) = self.A_log.shape\n",
    "\n",
    "        # Compute ∆ A B C D, the state space parameters.\n",
    "        #     A, D are input independent (see Mamba paper [1] Section 3.5.2 \"Interpretation of A\" for why A isn't selective)\n",
    "        #     ∆, B, C are input-dependent (this is a key difference between Mamba and the linear time invariant S4,\n",
    "        #                                  and is why Mamba is called **selective** state spaces)\n",
    "        \n",
    "        A = -torch.exp(self.A_log.float())  # shape (d_in, n)\n",
    "        D = self.D.float()\n",
    "\n",
    "        x_dbl = self.x_proj(x)  # (b, l, dt_rank + 2*n)\n",
    "        \n",
    "        (delta, B, C) = x_dbl.split(split_size=[self.dt_rank, n, n], dim=-1)  # delta: (b, l, dt_rank). B, C: (b, l, n)\n",
    "        delta = F.softplus(self.dt_proj(delta))  # (b, l, d_in)\n",
    "        \n",
    "        y = self.selective_scan(x, delta, A, B, C, D)  # This is similar to run_SSM(A, B, C, u) in The Annotated S4 [2]\n",
    "        \n",
    "        return y\n",
    "\n",
    "    \n",
    "    def selective_scan(self, u, delta, A, B, C, D):\n",
    "        \"\"\"Does selective scan algorithm. See:\n",
    "            - Section 2 State Space Models in the Mamba paper [1]\n",
    "            - Algorithm 2 in Section 3.2 in the Mamba paper [1]\n",
    "            - run_SSM(A, B, C, u) in The Annotated S4 [2]\n",
    "\n",
    "        This is the classic discrete state space formula:\n",
    "            x(t + 1) = Ax(t) + Bu(t)\n",
    "            y(t)     = Cx(t) + Du(t)\n",
    "        except B and C (and the step size delta, which is used for discretization) are dependent on the input x(t).\n",
    "    \n",
    "        Args:\n",
    "            u: shape (b, l, d_in)    (See Glossary at top for definitions of b, l, d_in, n...)\n",
    "            delta: shape (b, l, d_in)\n",
    "            A: shape (d_in, n)\n",
    "            B: shape (b, l, n)\n",
    "            C: shape (b, l, n)\n",
    "            D: shape (d_in,)\n",
    "    \n",
    "        Returns:\n",
    "            output: shape (b, l, d_in)\n",
    "    \n",
    "        Official Implementation:\n",
    "            selective_scan_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L86\n",
    "            Note: I refactored some parts out of `selective_scan_ref` out, so the functionality doesn't match exactly.\n",
    "            \n",
    "        \"\"\"\n",
    "        (b, l, d_in) = u.shape\n",
    "        n = A.shape[1]\n",
    "        \n",
    "        # Discretize continuous parameters (A, B)\n",
    "        # - A is discretized using zero-order hold (ZOH) discretization (see Section 2 Equation 4 in the Mamba paper [1])\n",
    "        # - B is discretized using a simplified Euler discretization instead of ZOH. From a discussion with authors:\n",
    "        #   \"A is the more important term and the performance doesn't change much with the simplification on B\"\n",
    "        deltaA = torch.exp(einsum(delta, A, 'b l d_in, d_in n -> b l d_in n'))\n",
    "        deltaB_u = einsum(delta, B, u, 'b l d_in, b l n, b l d_in -> b l d_in n')\n",
    "        \n",
    "        # Perform selective scan (see scan_SSM() in The Annotated S4 [2])\n",
    "        # Note that the below is sequential, while the official implementation does a much faster parallel scan that\n",
    "        # is additionally hardware-aware (like FlashAttention).\n",
    "        x = torch.zeros((b, d_in, n), device=deltaA.device)\n",
    "        ys = []    \n",
    "        for i in range(l):\n",
    "            x = deltaA[:, i] * x + deltaB_u[:, i]\n",
    "            y = einsum(x, C[:, i, :], 'b d_in n, b n -> b d_in')\n",
    "            ys.append(y)\n",
    "        y = torch.stack(ys, dim=1)  # shape (b, l, d_in)\n",
    "        \n",
    "        y = y + u * D\n",
    "    \n",
    "        return y\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model: int,\n",
    "                 eps: float = 1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(d_model))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps) * self.weight\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ec4da3-acb9-4721-8ce7-f8391c951781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overlap(interval1, interval2):\n",
    "    # Determine if there is an intersection\n",
    "    if interval1[1] < interval2[0] or interval2[1] < interval1[0]:\n",
    "        return 0\n",
    "    \n",
    "    # compute the start and the end of the overlap\n",
    "    start = max(interval1[0], interval2[0])\n",
    "    end = min(interval1[1], interval2[1])\n",
    "    \n",
    "    # compute the size of overlap\n",
    "    overlap = end - start + 1\n",
    "    \n",
    "    return overlap\n",
    "\n",
    "def check_overlap(interval1_np_list, interval2):\n",
    "    # Determin if there is an intersection of length 0.1 s\n",
    "    flag = True\n",
    "    for i in range( len(interval1_np_list[0]) ):\n",
    "        if compute_overlap([interval1_np_list[0][i], interval1_np_list[1][i]], interval2) >= NEW_SAMP_RATE/10:\n",
    "            return i\n",
    "\n",
    "    return -1\n",
    "\n",
    "\n",
    "\n",
    "def get_names( ch_num, l ):\n",
    "    name_list = []\n",
    "    for i in range(ch_num):\n",
    "        name_list.append( l[i]['name'][0] )\n",
    "        # print(l[i]['name'][0])\n",
    "    return name_list\n",
    "\n",
    "\n",
    "def top_n_elements(lists, n=6):\n",
    "   \n",
    "    overall_counter = Counter()\n",
    "    \n",
    " \n",
    "    for sublist in lists:\n",
    "        overall_counter.update(get_names(n, sublist))\n",
    "\n",
    " \n",
    "    top_elements_with_counts = overall_counter.most_common(n)\n",
    "\n",
    "    top_elements = [element for element, count in top_elements_with_counts]\n",
    "    counts = [count for element, count in top_elements_with_counts]\n",
    "    \n",
    "    return top_elements, counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc9a737d-b2b1-4d46-bec9-f5b3deb4de81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c155c4-fd01-4332-bb3d-b567798284ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListMerger:\n",
    "    def __init__(self, list1, list2):\n",
    "        self.list1 = list1\n",
    "        self.list2 = list2\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, slice):\n",
    "            # 处理切片\n",
    "            return [self[i] for i in range(*index.indices(len(self)))]\n",
    "        elif index < len(self.list1):\n",
    "            return self.list1[index]\n",
    "        else:\n",
    "            return self.list2[index - len(self.list1)]\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回合并后的列表的总长度\n",
    "        return len(self.list1) + len(self.list2)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.list1 + self.list2)\n",
    "\n",
    "class MergedDataset(Dataset):\n",
    "    def __init__(self, merger, labels, indices):\n",
    "        \"\"\"\n",
    "        :param merger: ListMerger 实例，包含合并后的数据\n",
    "        :param indices: 要使用的索引列表\n",
    "        \"\"\"\n",
    "        self.merger = merger\n",
    "        self.labels = labels\n",
    "        self.indices = indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 获取索引\n",
    "        index = self.indices[idx]\n",
    "        # 返回合并后的特征和标签\n",
    "        return self.merger[index], self.labels[index]\n",
    "\n",
    "def do_overlap( original_seq, seg_len, overlap_len ):\n",
    "    '''\n",
    "    Input:\n",
    "        original_seq: 2d tensor, [ch, seq_len]\n",
    "        overlap_len: float, overlapping length of 2 successive segments\n",
    "    Outputs:\n",
    "        res: a list of tensors\n",
    "    '''\n",
    "    res = []\n",
    "\n",
    "    for i in range( 0, original_seq.shape[1], seg_len-overlap_len ):\n",
    "        if original_seq.shape[1] - i < seg_len:\n",
    "            break\n",
    "        res.append( original_seq[:, i:(i+seg_len)] )\n",
    "\n",
    "    return res\n",
    "\n",
    "def read_edf_data_separately( data_folder, patient_to_use_list, COMMON_CH, SEG_TIME ):\n",
    "    # These files have no common channels with other files\n",
    "    FILE_EXCLUDED = ['chb12_27.edf', 'chb12_28.edf', 'chb12_29.edf'] \n",
    "\n",
    "    SAMPLE_RATE = 256\n",
    "    DOWN_SAMP_RATE = 1\n",
    "    NEW_SAMP_RATE = int(SAMPLE_RATE / DOWN_SAMP_RATE)\n",
    "    \n",
    "    SEG_LEN = NEW_SAMP_RATE * SEG_TIME\n",
    "    \n",
    "    # STEP_FOR_OVERLAP = int(NEW_SAMP_RATE * (SEG_TIME - OVERLAP_TIME))\n",
    "    # STEP_NO_OVERLAP  = SEG_LEN\n",
    "    \n",
    "    SPH = 30 * 60 * NEW_SAMP_RATE# Seizure Prediction Horizon (SPH)\n",
    "    # PIL = (15+SPH) * 60 * NEW_SAMP_RATE# Pre-ictal interval (PIL)\n",
    "    # POST_ICTAL_LEN = 15 * 60 * NEW_SAMP_RATE\n",
    "    \n",
    "    raws = []\n",
    "    file_names = []\n",
    "    labels = []\n",
    "    sec_seizure = {}\n",
    "\n",
    "    seizure_cnt = 0\n",
    "    \n",
    "    for patient_to_use in patient_to_use_list:\n",
    "        patient_path_folder = os.path.join(data_folder, patient_to_use)\n",
    "        # extract seizure information from summary\n",
    "        summary_path = os.path.join(patient_path_folder, patient_to_use+\"-summary.txt\")\n",
    "        with open(summary_path, 'r') as file:\n",
    "            content = file.read()\n",
    "        sections = content.split('\\n\\n')\n",
    "        for section in sections:\n",
    "            if (\"Seizure Start Time\" in section) or (\"Seizure 1 Start Time\" in section):\n",
    "                lines = section.split('\\n')\n",
    "                temp_name = ''\n",
    "                for i, line in enumerate(lines):\n",
    "                    if \"File Name:\" in line:\n",
    "                        temp_name = line.replace('File Name: ', '')\n",
    "                        sec_seizure[temp_name] = {}\n",
    "                        sec_seizure[temp_name]['start'] = []\n",
    "                        sec_seizure[temp_name]['end'] = []\n",
    "                    elif (\"Seizure\" in line) and (\"Start Time\" in line):\n",
    "                        parts = line.split(\":\")\n",
    "                        sec_seizure[temp_name]['start'].append( int(''.join(filter(str.isdigit, parts[1]))) )\n",
    "                        parts_end = lines[i+1].split(\":\")\n",
    "                        sec_seizure[temp_name]['end'].append( int(''.join(filter(str.isdigit, parts_end[1]))) )\n",
    "                        seizure_cnt += 1\n",
    "                        \n",
    "                        if seizure_cnt == SEIZURE_FOR_TEST:\n",
    "                            sec_seizure[temp_name]['for_test'] = len(sec_seizure[temp_name]['start'])-1\n",
    "\n",
    "                        # print(sec_seizure[temp_name])\n",
    "        # read edf data\n",
    "        for file in os.listdir(patient_path_folder):\n",
    "            if file.endswith('.edf') and file not in FILE_EXCLUDED:\n",
    "                file_path = os.path.join(patient_path_folder, file)\n",
    "                raw = mne.io.read_raw_edf(file_path)\n",
    "                raws.append(raw.pick(COMMON_CH))\n",
    "                file_names.append(file)\n",
    "                if file in sec_seizure:\n",
    "                    labels.append({**sec_seizure[file], 'name':file})\n",
    "                else:\n",
    "                    labels.append('')\n",
    "            \n",
    "    # split the data into 15 sec segments\n",
    "    segments_inter = []\n",
    "    segments_pre   = []\n",
    "    # seg_labels = []\n",
    "    \n",
    "    one_patient_segs_inter = []\n",
    "    one_patient_segs_pre = []\n",
    "    # one_patient_labels = []\n",
    "    total_len_inter = 0\n",
    "    total_len_pre = 0\n",
    "    \n",
    "    for index, (raw, label, file_name) in enumerate(zip(raws, labels, file_names)):\n",
    "        # raw.load_data()\n",
    "        # raw.filter(1, 45, fir_design='firwin')\n",
    "        data = raw.get_data()#[:, ::DOWN_SAMP_RATE]\n",
    "        data = data * 1e4\n",
    "\n",
    "        if label == '':\n",
    "            one_patient_segs_inter.append( torch.tensor(data, dtype=torch.float32) ) \n",
    "            total_len_inter += data.shape[1]\n",
    "        else:\n",
    "            # print(label)\n",
    "            # split data with 4 sec overlapping\n",
    "            seizure_start = np.array( label['start'] ) * NEW_SAMP_RATE\n",
    "            seizure_end   = np.array( label['end'] ) * NEW_SAMP_RATE\n",
    "            # print( seizure_start-SPH, seizure_start)\n",
    "\n",
    "            last_end = -1\n",
    "            for sez_i in range( len( seizure_start ) ):\n",
    "                beg = seizure_start[sez_i] - SPH\n",
    "                end = seizure_start[sez_i]\n",
    "                # print( beg, end )\n",
    "\n",
    "                # If the gap between the start of seizure and start of the file is less than SPH,\n",
    "                # you should manually modify the summary file first. Add the seizure start and end\n",
    "                # time of current file to the last file but add the length of the last file and the \n",
    "                # gap between the end of the last file and the start of the current file\n",
    "                if beg < 0:\n",
    "                    # temp_data = one_patient_segs_inter.pop().numpy()\n",
    "                    # total_len_inter -= temp_data.shape[1]\n",
    "                    \n",
    "                    # one_patient_segs_pre.append( torch.tensor(temp_data[:, beg:], dtype=torch.float32) )\n",
    "                    # total_len_pre += one_patient_segs_pre[-1].shape[1]\n",
    "                    # print( one_patient_segs_pre[-1].shape[1], SEG_LEN )\n",
    "                    one_patient_segs_pre.append( torch.tensor(data[:, 0:seizure_start[sez_i]], dtype=torch.float32) )\n",
    "                    total_len_pre += seizure_start[sez_i]\n",
    "\n",
    "                    # one_patient_segs_inter.append( torch.tensor(temp_data[:, 0:-SEG_LEN], dtype=torch.float32) )\n",
    "                    # total_len_inter += one_patient_segs_inter[-1].shape[1]\n",
    "                else:\n",
    "                    one_patient_segs_pre.append( torch.tensor(data[:, beg:end+1], dtype=torch.float32) )\n",
    "                    total_len_pre += one_patient_segs_pre[-1].shape[1]\n",
    "                    one_patient_segs_inter.append( torch.tensor(data[:, (last_end+1) : beg], dtype=torch.float32) )\n",
    "                    total_len_inter += one_patient_segs_inter[-1].shape[1]\n",
    "                \n",
    "                last_end = seizure_end[sez_i]\n",
    "\n",
    "            one_patient_segs_inter.append( torch.tensor(data[:, (last_end+1):], dtype=torch.float32) ) \n",
    "            total_len_inter += one_patient_segs_inter[-1].shape[1]\n",
    "\n",
    "        # Finish one patient or finish the last file\n",
    "        if (index != 0) and (file_name[0:5] != file_names[index-1][0:5]):\n",
    "            # segments.append( one_patient_segs )\n",
    "            # seg_labels.append( one_patient_labels )\n",
    "            segments_inter.extend( one_patient_segs_inter )\n",
    "            segments_pre.extend( one_patient_segs_pre )\n",
    "            # seg_labels.extend( one_patient_labels )\n",
    "            one_patient_segs_inter = []\n",
    "            one_patient_segs_pre = []\n",
    "            # one_patient_labels = []\n",
    "            # print(index, file_name, file_names[index-1][0:5])\n",
    "        if index == len(raws)-1:\n",
    "            # segments.append( one_patient_segs )\n",
    "            # seg_labels.append( one_patient_labels )\n",
    "            segments_inter.extend( one_patient_segs_inter )\n",
    "            segments_pre.extend( one_patient_segs_pre )\n",
    "            # seg_labels.extend( one_patient_labels )\n",
    "            one_patient_segs_inter = []\n",
    "            one_patient_segs_pre = []\n",
    "            # one_patient_labels = []\n",
    "            # print(index, file_name, file_names[index-1][0:5])\n",
    "\n",
    "    segments_pre_overlap = []\n",
    "    segments_inter_no_overlap = []\n",
    "    step_for_overlap = int( SEG_LEN / ( total_len_inter / total_len_pre ) )\n",
    "    print(\"step_for_overlap:\", step_for_overlap)\n",
    "    print(total_len_inter, total_len_pre)\n",
    "    while segments_inter or segments_pre:\n",
    "        if segments_pre:\n",
    "            # segments_pre_overlap.append( do_overlap( seg_pre, SEG_LEN, OVERLAP_TIME*NEW_SAMP_RATE ) )\n",
    "            segments_pre_overlap.extend( do_overlap( segments_pre[0], SEG_LEN, SEG_LEN-step_for_overlap) ) #OVERLAP_TIME*NEW_SAMP_RATE ) )\n",
    "            segments_pre.pop(0)\n",
    "            # print( len(segments_pre_overlap) )\n",
    "        if segments_inter:\n",
    "            # segments_inter_no_overlap.append( do_overlap( segments_inter[0], SEG_LEN, OVERLAP_TIME*NEW_SAMP_RATE ) )\n",
    "            segments_inter_no_overlap.extend( do_overlap( segments_inter[0], SEG_LEN, 0 ) )\n",
    "            segments_inter.pop(0)\n",
    "            # print( len(segments_inter_no_overlap) )\n",
    "    \n",
    "    \n",
    "    return segments_inter_no_overlap, segments_pre_overlap\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "789ef271-004c-4216-84f9-6a1ad3c34ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://www.kaggle.com/code/debarshichanda/pytorch-supervised-contrastive-learning\n",
    "class SupervisedContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.1):\n",
    "        super(SupervisedContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, feature_vectors, labels):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = F.normalize(feature_vectors, p=2, dim=1)\n",
    "        # Compute logits\n",
    "        logits = torch.div(\n",
    "            torch.matmul(\n",
    "                feature_vectors_normalized, torch.transpose(feature_vectors_normalized, 0, 1)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        # print( logits.shape, labels.shape )\n",
    "        return losses.NTXentLoss(temperature=self.temperature)(logits, labels)\n",
    "# super_contras = SupervisedContrastiveLoss(0.1)\n",
    "# super_contras( x, label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a89e2a9-b473-4a0d-b9c9-e0f49ad3cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def count_label_np(one_hot_data, label):\n",
    "    labels = np.argmax(one_hot_data, axis=1)  \n",
    "    count = np.sum(labels == label)  \n",
    "    return count  \n",
    "\n",
    "def calculate_accuracy_np(y_true, y_pred):\n",
    "    labels_true = y_true #np.argmax(y_true, axis=1)  \n",
    "    labels_pred = y_pred #np.argmax(y_pred, axis=1)  \n",
    "    accuracy = np.sum(labels_true.T == labels_pred) / len(labels_true)  \n",
    "    return accuracy\n",
    "\n",
    "def calculate_sensitivity_np(y_true, y_pred, class_index):\n",
    "    # labels_true = np.argmax(y_true, axis=1)  \n",
    "    # labels_pred = np.argmax(y_pred, axis=1)  \n",
    "    labels_true = y_true #np.argmax(y_true, axis=1)  \n",
    "    labels_pred = y_pred #np.argmax(y_pred, axis=1)  \n",
    "    positive_labels = (labels_true == class_index)  \n",
    "    true_positive = np.sum((labels_pred == labels_true) * positive_labels)  \n",
    "    false_negative = np.sum((labels_pred != labels_true) * positive_labels)  \n",
    "    if (true_positive + false_negative) == 0:\n",
    "        return -1\n",
    "    sensitivity = true_positive / (true_positive + false_negative)  \n",
    "    return sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc048ee2-5ea2-420b-887a-60b39357b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 dimentional version + Mamba\n",
    "## Patient-Specific Seizure Prediction via Adder Network and Supervised Contrastive Learning\n",
    "## ADDNet-SCL-1d\n",
    "\n",
    "class OneDCNN(nn.Module):\n",
    "    def __init__(self, input_channels=3):\n",
    "        super(OneDCNN, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "      \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_channels, out_channels=16, kernel_size=21, stride=1, padding=10),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=8, stride=8)\n",
    "        )\n",
    "\n",
    "        self.conv2_1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=16, out_channels=16, kernel_size=1, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2_2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=16, out_channels=16, kernel_size=11, stride=1, padding=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "\n",
    "        self.conv4_1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=1, stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv4_2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, stride=2, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # self.conv5_1 = nn.Sequential(\n",
    "        #     nn.Conv1d(in_channels=32, out_channels=32, kernel_size=1, stride=2),\n",
    "        #     nn.ReLU()\n",
    "        # )\n",
    "        # self.conv5_2 = nn.Sequential(\n",
    "        #     nn.Conv1d(in_channels=32, out_channels=32, kernel_size=5, stride=2, padding=2),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.ReLU()\n",
    "        # )\n",
    "\n",
    "        self.mixer = MambaBlock(32)\n",
    "        self.norm = RMSNorm(32)\n",
    "\n",
    "        self.adaptive_avg_pool = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.unsqueeze(1)\n",
    "        # print(x.shape)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.pool3( self.conv2_1(x)+self.conv2_2(x) )\n",
    "\n",
    "        x = self.conv4_1(x)+self.conv4_2(x)\n",
    "\n",
    "        # x = self.conv5_1(x)+self.conv5_2(x)\n",
    "\n",
    "        # x = [batch, channels, seq_len]\n",
    "        x = x.permute(0, 2, 1) # [batch, seq_len, channels]\n",
    "        x = self.mixer(self.norm(x)) + x\n",
    "        x = x.permute(0, 2, 1) # [batch, channels, seq_len]\n",
    "\n",
    "        x = self.adaptive_avg_pool( x )\n",
    "        \n",
    "        x_digits = x.contiguous().view(x.size(0), -1)\n",
    "        # print(f'x.shape = {x.shape}')\n",
    "        x_res = self.classifier(x_digits)\n",
    "        return x_res, x_digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88b07266-368d-4127-b179-9751ee2af8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chb07']\n",
      "step_for_overlap: 23\n",
      "60329725 1382403\n",
      "\n",
      "Fold [1/10] Epoch [1/30], time cost: 75.8651,\n",
      " Train Cross Loss: 0.2338, Train Contras Loss: 1.3188 Train acc:  0.9030,\n",
      " Val Cross loss: 0.1426, Val Contras loss: 0.8427, Val accuracy: 0.9474, Sensitivity: 0.9853, Specificity: 0.9089\n",
      "\n",
      "Fold [1/10] Epoch [2/30], time cost: 68.0297,\n",
      " Train Cross Loss: 0.1439, Train Contras Loss: 0.8184 Train acc:  0.9465,\n",
      " Val Cross loss: 0.1183, Val Contras loss: 0.7026, Val accuracy: 0.9577, Sensitivity: 0.9888, Specificity: 0.9262\n",
      "\n",
      "Fold [1/10] Epoch [3/30], time cost: 69.4112,\n",
      " Train Cross Loss: 0.1233, Train Contras Loss: 0.6780 Train acc:  0.9559,\n",
      " Val Cross loss: 0.0939, Val Contras loss: 0.5947, Val accuracy: 0.9680, Sensitivity: 0.9827, Specificity: 0.9531\n",
      "\n",
      "Fold [1/10] Epoch [4/30], time cost: 68.7489,\n",
      " Train Cross Loss: 0.1098, Train Contras Loss: 0.5922 Train acc:  0.9614,\n",
      " Val Cross loss: 0.0895, Val Contras loss: 0.5269, Val accuracy: 0.9707, Sensitivity: 0.9723, Specificity: 0.9691\n",
      "\n",
      "Fold [1/10] Epoch [5/30], time cost: 71.2240,\n",
      " Train Cross Loss: 0.1010, Train Contras Loss: 0.5344 Train acc:  0.9653,\n",
      " Val Cross loss: 0.1336, Val Contras loss: 0.5914, Val accuracy: 0.9471, Sensitivity: 0.9999, Specificity: 0.8936\n",
      "\n",
      "Fold [1/10] Epoch [6/30], time cost: 74.3792,\n",
      " Train Cross Loss: 0.0906, Train Contras Loss: 0.4714 Train acc:  0.9684,\n",
      " Val Cross loss: 0.0775, Val Contras loss: 0.4295, Val accuracy: 0.9758, Sensitivity: 0.9858, Specificity: 0.9657\n",
      "\n",
      "Fold [1/10] Epoch [7/30], time cost: 70.5065,\n",
      " Train Cross Loss: 0.0864, Train Contras Loss: 0.4355 Train acc:  0.9706,\n",
      " Val Cross loss: 0.0689, Val Contras loss: 0.3805, Val accuracy: 0.9771, Sensitivity: 0.9864, Specificity: 0.9678\n",
      "\n",
      "Fold [1/10] Epoch [8/30], time cost: 67.2826,\n",
      " Train Cross Loss: 0.0786, Train Contras Loss: 0.3950 Train acc:  0.9738,\n",
      " Val Cross loss: 0.0698, Val Contras loss: 0.3718, Val accuracy: 0.9777, Sensitivity: 0.9970, Specificity: 0.9581\n",
      "\n",
      "Fold [1/10] Epoch [9/30], time cost: 67.0938,\n",
      " Train Cross Loss: 0.0733, Train Contras Loss: 0.3631 Train acc:  0.9757,\n",
      " Val Cross loss: 0.0842, Val Contras loss: 0.4025, Val accuracy: 0.9725, Sensitivity: 0.9654, Specificity: 0.9797\n",
      "\n",
      "Fold [1/10] Epoch [10/30], time cost: 67.5723,\n",
      " Train Cross Loss: 0.0695, Train Contras Loss: 0.3412 Train acc:  0.9775,\n",
      " Val Cross loss: 0.0625, Val Contras loss: 0.3287, Val accuracy: 0.9807, Sensitivity: 0.9866, Specificity: 0.9748\n",
      "\n",
      "Fold [1/10] Epoch [11/30], time cost: 66.7898,\n",
      " Train Cross Loss: 0.0690, Train Contras Loss: 0.3260 Train acc:  0.9775,\n",
      " Val Cross loss: 0.0611, Val Contras loss: 0.3316, Val accuracy: 0.9819, Sensitivity: 0.9901, Specificity: 0.9735\n",
      "\n",
      "Fold [1/10] Epoch [12/30], time cost: 68.8524,\n",
      " Train Cross Loss: 0.0633, Train Contras Loss: 0.2948 Train acc:  0.9803,\n",
      " Val Cross loss: 0.0831, Val Contras loss: 0.3851, Val accuracy: 0.9721, Sensitivity: 0.9994, Specificity: 0.9444\n",
      "\n",
      "Fold [1/10] Epoch [13/30], time cost: 70.4424,\n",
      " Train Cross Loss: 0.0599, Train Contras Loss: 0.2787 Train acc:  0.9815,\n",
      " Val Cross loss: 0.0638, Val Contras loss: 0.3067, Val accuracy: 0.9824, Sensitivity: 0.9992, Specificity: 0.9653\n",
      "\n",
      "Fold [1/10] Epoch [14/30], time cost: 72.8871,\n",
      " Train Cross Loss: 0.0570, Train Contras Loss: 0.2633 Train acc:  0.9821,\n",
      " Val Cross loss: 0.0669, Val Contras loss: 0.3301, Val accuracy: 0.9787, Sensitivity: 0.9994, Specificity: 0.9576\n",
      "\n",
      "Fold [1/10] Epoch [15/30], time cost: 72.2576,\n",
      " Train Cross Loss: 0.0576, Train Contras Loss: 0.2664 Train acc:  0.9819,\n",
      " Val Cross loss: 0.0938, Val Contras loss: 0.3961, Val accuracy: 0.9716, Sensitivity: 0.9999, Specificity: 0.9429\n",
      "\n",
      "Fold [1/10] Epoch [16/30], time cost: 71.3552,\n",
      " Train Cross Loss: 0.0537, Train Contras Loss: 0.2433 Train acc:  0.9835,\n",
      " Val Cross loss: 0.0697, Val Contras loss: 0.3086, Val accuracy: 0.9767, Sensitivity: 0.9999, Specificity: 0.9532\n",
      "\n",
      "Fold [1/10] Epoch [17/30], time cost: 71.5720,\n",
      " Train Cross Loss: 0.0523, Train Contras Loss: 0.2360 Train acc:  0.9843,\n",
      " Val Cross loss: 0.0767, Val Contras loss: 0.3571, Val accuracy: 0.9761, Sensitivity: 0.9988, Specificity: 0.9531\n",
      "\n",
      "Fold [1/10] Epoch [18/30], time cost: 72.5636,\n",
      " Train Cross Loss: 0.0489, Train Contras Loss: 0.2288 Train acc:  0.9847,\n",
      " Val Cross loss: 0.0587, Val Contras loss: 0.3254, Val accuracy: 0.9816, Sensitivity: 0.9860, Specificity: 0.9772\n",
      "\n",
      "Fold [1/10] Epoch [19/30], time cost: 69.1934,\n",
      " Train Cross Loss: 0.0514, Train Contras Loss: 0.2293 Train acc:  0.9844,\n",
      " Val Cross loss: 0.0697, Val Contras loss: 0.3204, Val accuracy: 0.9773, Sensitivity: 0.9993, Specificity: 0.9550\n",
      "\n",
      "Fold [1/10] Epoch [20/30], time cost: 70.6291,\n",
      " Train Cross Loss: 0.0481, Train Contras Loss: 0.2084 Train acc:  0.9849,\n",
      " Val Cross loss: 0.0507, Val Contras loss: 0.2524, Val accuracy: 0.9848, Sensitivity: 0.9968, Specificity: 0.9726\n",
      "\n",
      "Fold [1/10] Epoch [21/30], time cost: 70.4004,\n",
      " Train Cross Loss: 0.0467, Train Contras Loss: 0.2059 Train acc:  0.9857,\n",
      " Val Cross loss: 0.0493, Val Contras loss: 0.2405, Val accuracy: 0.9844, Sensitivity: 0.9987, Specificity: 0.9700\n",
      "\n",
      "Fold [1/10] Epoch [22/30], time cost: 72.5148,\n",
      " Train Cross Loss: 0.0451, Train Contras Loss: 0.1961 Train acc:  0.9861,\n",
      " Val Cross loss: 0.0563, Val Contras loss: 0.3119, Val accuracy: 0.9828, Sensitivity: 0.9911, Specificity: 0.9744\n",
      "\n",
      "Fold [1/10] Epoch [23/30], time cost: 72.6491,\n",
      " Train Cross Loss: 0.0433, Train Contras Loss: 0.1909 Train acc:  0.9866,\n",
      " Val Cross loss: 0.0878, Val Contras loss: 0.3784, Val accuracy: 0.9691, Sensitivity: 0.9522, Specificity: 0.9863\n",
      "\n",
      "Fold [1/10] Epoch [24/30], time cost: 68.8996,\n",
      " Train Cross Loss: 0.0429, Train Contras Loss: 0.1884 Train acc:  0.9872,\n",
      " Val Cross loss: 0.1005, Val Contras loss: 0.3974, Val accuracy: 0.9690, Sensitivity: 1.0000, Specificity: 0.9376\n",
      "\n",
      "Fold [1/10] Epoch [25/30], time cost: 70.8728,\n",
      " Train Cross Loss: 0.0428, Train Contras Loss: 0.1806 Train acc:  0.9869,\n",
      " Val Cross loss: 0.0473, Val Contras loss: 0.2485, Val accuracy: 0.9850, Sensitivity: 0.9883, Specificity: 0.9816\n",
      "\n",
      "Fold [1/10] Epoch [26/30], time cost: 72.9988,\n",
      " Train Cross Loss: 0.0403, Train Contras Loss: 0.1707 Train acc:  0.9878,\n",
      " Val Cross loss: 0.0500, Val Contras loss: 0.2591, Val accuracy: 0.9851, Sensitivity: 0.9891, Specificity: 0.9810\n",
      "\n",
      "Fold [1/10] Epoch [27/30], time cost: 73.4059,\n",
      " Train Cross Loss: 0.0393, Train Contras Loss: 0.1650 Train acc:  0.9880,\n",
      " Val Cross loss: 0.0855, Val Contras loss: 0.3907, Val accuracy: 0.9725, Sensitivity: 0.9996, Specificity: 0.9449\n",
      "\n",
      "Fold [1/10] Epoch [28/30], time cost: 72.5434,\n",
      " Train Cross Loss: 0.0414, Train Contras Loss: 0.1719 Train acc:  0.9870,\n",
      " Val Cross loss: 0.0474, Val Contras loss: 0.2544, Val accuracy: 0.9858, Sensitivity: 0.9965, Specificity: 0.9750\n",
      "\n",
      "Fold [1/10] Epoch [29/30], time cost: 73.2145,\n",
      " Train Cross Loss: 0.0363, Train Contras Loss: 0.1549 Train acc:  0.9893,\n",
      " Val Cross loss: 0.0522, Val Contras loss: 0.2588, Val accuracy: 0.9847, Sensitivity: 0.9881, Specificity: 0.9812\n",
      "\n",
      "Fold [1/10] Epoch [30/30], time cost: 74.1290,\n",
      " Train Cross Loss: 0.0362, Train Contras Loss: 0.1492 Train acc:  0.9892,\n",
      " Val Cross loss: 0.0590, Val Contras loss: 0.2810, Val accuracy: 0.9825, Sensitivity: 0.9824, Specificity: 0.9827\n",
      "['C4-P4', 'CZ-PZ', 'P4-O2', 'P8-O2', 'P7-O1', 'P3-O1']\n",
      "\n",
      "***********\n",
      "Best epoch: 27 Acc: 0.9857937286789102 Sensitivity for pre-ictal: 0.9964749536178108 Specificity: 0.974950560316414\n",
      "***********\n",
      "\n",
      "Test Loss: 0.0492, Test accuracy: 0.9862, Sensitivity: 0.9963, Specificity: 0.9759\n",
      "\n",
      "Fold [2/10] Epoch [1/30], time cost: 72.1812,\n",
      " Train Cross Loss: 0.2377, Train Contras Loss: 1.3173 Train acc:  0.9026,\n",
      " Val Cross loss: 0.1405, Val Contras loss: 0.7936, Val accuracy: 0.9492, Sensitivity: 0.9443, Specificity: 0.9543\n",
      "\n",
      "Fold [2/10] Epoch [2/30], time cost: 73.2393,\n",
      " Train Cross Loss: 0.1417, Train Contras Loss: 0.7917 Train acc:  0.9465,\n",
      " Val Cross loss: 0.1103, Val Contras loss: 0.6701, Val accuracy: 0.9613, Sensitivity: 0.9774, Specificity: 0.9449\n",
      "\n",
      "Fold [2/10] Epoch [3/30], time cost: 73.0772,\n",
      " Train Cross Loss: 0.1188, Train Contras Loss: 0.6493 Train acc:  0.9570,\n",
      " Val Cross loss: 0.1007, Val Contras loss: 0.6089, Val accuracy: 0.9651, Sensitivity: 0.9838, Specificity: 0.9462\n",
      "\n",
      "Fold [2/10] Epoch [4/30], time cost: 73.5804,\n",
      " Train Cross Loss: 0.1121, Train Contras Loss: 0.5786 Train acc:  0.9603,\n",
      " Val Cross loss: 0.0923, Val Contras loss: 0.5510, Val accuracy: 0.9686, Sensitivity: 0.9917, Specificity: 0.9453\n",
      "\n",
      "Fold [2/10] Epoch [5/30], time cost: 71.5248,\n",
      " Train Cross Loss: 0.1004, Train Contras Loss: 0.5080 Train acc:  0.9648,\n",
      " Val Cross loss: 0.1439, Val Contras loss: 0.6686, Val accuracy: 0.9468, Sensitivity: 0.9985, Specificity: 0.8944\n",
      "\n",
      "Fold [2/10] Epoch [6/30], time cost: 73.1542,\n",
      " Train Cross Loss: 0.0899, Train Contras Loss: 0.4604 Train acc:  0.9689,\n",
      " Val Cross loss: 0.0802, Val Contras loss: 0.4572, Val accuracy: 0.9736, Sensitivity: 0.9927, Specificity: 0.9544\n",
      "\n",
      "Fold [2/10] Epoch [7/30], time cost: 69.6654,\n",
      " Train Cross Loss: 0.0846, Train Contras Loss: 0.4220 Train acc:  0.9716,\n",
      " Val Cross loss: 0.0710, Val Contras loss: 0.4007, Val accuracy: 0.9775, Sensitivity: 0.9927, Specificity: 0.9622\n",
      "\n",
      "Fold [2/10] Epoch [8/30], time cost: 70.5354,\n",
      " Train Cross Loss: 0.0803, Train Contras Loss: 0.3876 Train acc:  0.9731,\n",
      " Val Cross loss: 0.0790, Val Contras loss: 0.4613, Val accuracy: 0.9728, Sensitivity: 0.9701, Specificity: 0.9755\n",
      "\n",
      "Fold [2/10] Epoch [9/30], time cost: 69.5191,\n",
      " Train Cross Loss: 0.0721, Train Contras Loss: 0.3513 Train acc:  0.9759,\n",
      " Val Cross loss: 0.0693, Val Contras loss: 0.3752, Val accuracy: 0.9772, Sensitivity: 0.9963, Specificity: 0.9580\n",
      "\n",
      "Fold [2/10] Epoch [10/30], time cost: 70.8217,\n",
      " Train Cross Loss: 0.0682, Train Contras Loss: 0.3293 Train acc:  0.9777,\n",
      " Val Cross loss: 0.1523, Val Contras loss: 0.5444, Val accuracy: 0.9477, Sensitivity: 1.0000, Specificity: 0.8947\n",
      "\n",
      "Fold [2/10] Epoch [11/30], time cost: 70.3822,\n",
      " Train Cross Loss: 0.0658, Train Contras Loss: 0.3090 Train acc:  0.9789,\n",
      " Val Cross loss: 0.1391, Val Contras loss: 0.5014, Val accuracy: 0.9456, Sensitivity: 0.9029, Specificity: 0.9888\n",
      "\n",
      "Fold [2/10] Epoch [12/30], time cost: 71.6752,\n",
      " Train Cross Loss: 0.0619, Train Contras Loss: 0.2921 Train acc:  0.9797,\n",
      " Val Cross loss: 0.0664, Val Contras loss: 0.3381, Val accuracy: 0.9792, Sensitivity: 0.9984, Specificity: 0.9597\n",
      "\n",
      "Fold [2/10] Epoch [13/30], time cost: 71.0789,\n",
      " Train Cross Loss: 0.0590, Train Contras Loss: 0.2759 Train acc:  0.9810,\n",
      " Val Cross loss: 0.0798, Val Contras loss: 0.4176, Val accuracy: 0.9723, Sensitivity: 0.9645, Specificity: 0.9802\n",
      "\n",
      "Fold [2/10] Epoch [14/30], time cost: 72.0572,\n",
      " Train Cross Loss: 0.0583, Train Contras Loss: 0.2632 Train acc:  0.9810,\n",
      " Val Cross loss: 0.0748, Val Contras loss: 0.3727, Val accuracy: 0.9746, Sensitivity: 0.9984, Specificity: 0.9505\n",
      "\n",
      "Fold [2/10] Epoch [15/30], time cost: 71.2565,\n",
      " Train Cross Loss: 0.0563, Train Contras Loss: 0.2516 Train acc:  0.9819,\n",
      " Val Cross loss: 0.0652, Val Contras loss: 0.3603, Val accuracy: 0.9792, Sensitivity: 0.9966, Specificity: 0.9616\n",
      "\n",
      "Fold [2/10] Epoch [16/30], time cost: 69.4107,\n",
      " Train Cross Loss: 0.0538, Train Contras Loss: 0.2423 Train acc:  0.9826,\n",
      " Val Cross loss: 0.0591, Val Contras loss: 0.3226, Val accuracy: 0.9802, Sensitivity: 0.9936, Specificity: 0.9666\n",
      "\n",
      "Fold [2/10] Epoch [17/30], time cost: 69.1894,\n",
      " Train Cross Loss: 0.0503, Train Contras Loss: 0.2256 Train acc:  0.9840,\n",
      " Val Cross loss: 0.0589, Val Contras loss: 0.3021, Val accuracy: 0.9816, Sensitivity: 0.9953, Specificity: 0.9678\n",
      "\n",
      "Fold [2/10] Epoch [18/30], time cost: 69.3460,\n",
      " Train Cross Loss: 0.0498, Train Contras Loss: 0.2192 Train acc:  0.9839,\n",
      " Val Cross loss: 0.0968, Val Contras loss: 0.3692, Val accuracy: 0.9632, Sensitivity: 0.9394, Specificity: 0.9873\n",
      "\n",
      "Fold [2/10] Epoch [19/30], time cost: 65.6090,\n",
      " Train Cross Loss: 0.0491, Train Contras Loss: 0.2074 Train acc:  0.9844,\n",
      " Val Cross loss: 0.0960, Val Contras loss: 0.4216, Val accuracy: 0.9686, Sensitivity: 0.9992, Specificity: 0.9376\n",
      "\n",
      "Fold [2/10] Epoch [20/30], time cost: 65.7949,\n",
      " Train Cross Loss: 0.0448, Train Contras Loss: 0.1937 Train acc:  0.9859,\n",
      " Val Cross loss: 0.0632, Val Contras loss: 0.2965, Val accuracy: 0.9793, Sensitivity: 0.9995, Specificity: 0.9589\n",
      "\n",
      "Fold [2/10] Epoch [21/30], time cost: 66.8066,\n",
      " Train Cross Loss: 0.0444, Train Contras Loss: 0.1939 Train acc:  0.9861,\n",
      " Val Cross loss: 0.0559, Val Contras loss: 0.3091, Val accuracy: 0.9823, Sensitivity: 0.9865, Specificity: 0.9780\n",
      "\n",
      "Fold [2/10] Epoch [22/30], time cost: 66.6165,\n",
      " Train Cross Loss: 0.0419, Train Contras Loss: 0.1784 Train acc:  0.9872,\n",
      " Val Cross loss: 0.0739, Val Contras loss: 0.3561, Val accuracy: 0.9773, Sensitivity: 0.9998, Specificity: 0.9546\n",
      "\n",
      "Fold [2/10] Epoch [23/30], time cost: 62.0803,\n",
      " Train Cross Loss: 0.0417, Train Contras Loss: 0.1778 Train acc:  0.9871,\n",
      " Val Cross loss: 0.0540, Val Contras loss: 0.2838, Val accuracy: 0.9834, Sensitivity: 0.9975, Specificity: 0.9691\n",
      "\n",
      "Fold [2/10] Epoch [24/30], time cost: 67.5839,\n",
      " Train Cross Loss: 0.0388, Train Contras Loss: 0.1658 Train acc:  0.9879,\n",
      " Val Cross loss: 0.0680, Val Contras loss: 0.3232, Val accuracy: 0.9771, Sensitivity: 0.9673, Specificity: 0.9869\n",
      "\n",
      "Fold [2/10] Epoch [25/30], time cost: 67.7732,\n",
      " Train Cross Loss: 0.0386, Train Contras Loss: 0.1602 Train acc:  0.9879,\n",
      " Val Cross loss: 0.0448, Val Contras loss: 0.2380, Val accuracy: 0.9865, Sensitivity: 0.9932, Specificity: 0.9797\n",
      "\n",
      "Fold [2/10] Epoch [26/30], time cost: 67.8742,\n",
      " Train Cross Loss: 0.0399, Train Contras Loss: 0.1625 Train acc:  0.9870,\n",
      " Val Cross loss: 0.0549, Val Contras loss: 0.2942, Val accuracy: 0.9828, Sensitivity: 0.9967, Specificity: 0.9688\n",
      "\n",
      "Fold [2/10] Epoch [27/30], time cost: 67.6711,\n",
      " Train Cross Loss: 0.0359, Train Contras Loss: 0.1488 Train acc:  0.9889,\n",
      " Val Cross loss: 0.0552, Val Contras loss: 0.2867, Val accuracy: 0.9837, Sensitivity: 0.9971, Specificity: 0.9701\n",
      "\n",
      "Fold [2/10] Epoch [28/30], time cost: 68.5602,\n",
      " Train Cross Loss: 0.0353, Train Contras Loss: 0.1435 Train acc:  0.9888,\n",
      " Val Cross loss: 0.0482, Val Contras loss: 0.2533, Val accuracy: 0.9863, Sensitivity: 0.9903, Specificity: 0.9821\n",
      "\n",
      "Fold [2/10] Epoch [29/30], time cost: 68.3478,\n",
      " Train Cross Loss: 0.0342, Train Contras Loss: 0.1441 Train acc:  0.9895,\n",
      " Val Cross loss: 0.0558, Val Contras loss: 0.2781, Val accuracy: 0.9833, Sensitivity: 0.9976, Specificity: 0.9689\n",
      "\n",
      "Fold [2/10] Epoch [30/30], time cost: 67.8124,\n",
      " Train Cross Loss: 0.0349, Train Contras Loss: 0.1439 Train acc:  0.9896,\n",
      " Val Cross loss: 0.0445, Val Contras loss: 0.2412, Val accuracy: 0.9865, Sensitivity: 0.9966, Specificity: 0.9763\n",
      "['C4-P4', 'CZ-PZ', 'P4-O2', 'P8-O2', 'P7-O1', 'P3-O1']\n",
      "\n",
      "***********\n",
      "Best epoch: 24 Acc: 0.9864946960138324 Sensitivity for pre-ictal: 0.9932206537890045 Specificity: 0.9796820618944596\n",
      "***********\n",
      "\n",
      "Test Loss: 0.0504, Test accuracy: 0.9854, Sensitivity: 0.9917, Specificity: 0.9790\n",
      "\n",
      "Fold [3/10] Epoch [1/30], time cost: 67.5390,\n",
      " Train Cross Loss: 0.2285, Train Contras Loss: 1.2880 Train acc:  0.9075,\n",
      " Val Cross loss: 0.1260, Val Contras loss: 0.7948, Val accuracy: 0.9549, Sensitivity: 0.9676, Specificity: 0.9417\n",
      "\n",
      "Fold [3/10] Epoch [2/30], time cost: 68.0615,\n",
      " Train Cross Loss: 0.1384, Train Contras Loss: 0.7694 Train acc:  0.9490,\n",
      " Val Cross loss: 0.1018, Val Contras loss: 0.5807, Val accuracy: 0.9666, Sensitivity: 0.9687, Specificity: 0.9644\n",
      "\n",
      "Fold [3/10] Epoch [3/30], time cost: 67.6140,\n",
      " Train Cross Loss: 0.1171, Train Contras Loss: 0.6256 Train acc:  0.9586,\n",
      " Val Cross loss: 0.0816, Val Contras loss: 0.4749, Val accuracy: 0.9749, Sensitivity: 0.9899, Specificity: 0.9593\n",
      "\n",
      "Fold [3/10] Epoch [4/30], time cost: 67.8021,\n",
      " Train Cross Loss: 0.0996, Train Contras Loss: 0.5298 Train acc:  0.9655,\n",
      " Val Cross loss: 0.0947, Val Contras loss: 0.5119, Val accuracy: 0.9657, Sensitivity: 0.9533, Specificity: 0.9786\n",
      "\n",
      "Fold [3/10] Epoch [5/30], time cost: 67.1507,\n",
      " Train Cross Loss: 0.0927, Train Contras Loss: 0.4801 Train acc:  0.9682,\n",
      " Val Cross loss: 0.0739, Val Contras loss: 0.4304, Val accuracy: 0.9757, Sensitivity: 0.9806, Specificity: 0.9705\n",
      "\n",
      "Fold [3/10] Epoch [6/30], time cost: 68.3352,\n",
      " Train Cross Loss: 0.0819, Train Contras Loss: 0.4168 Train acc:  0.9723,\n",
      " Val Cross loss: 0.1697, Val Contras loss: 0.7063, Val accuracy: 0.9397, Sensitivity: 0.9999, Specificity: 0.8774\n",
      "\n",
      "Fold [3/10] Epoch [7/30], time cost: 67.9525,\n",
      " Train Cross Loss: 0.0773, Train Contras Loss: 0.3832 Train acc:  0.9743,\n",
      " Val Cross loss: 0.1409, Val Contras loss: 0.6332, Val accuracy: 0.9545, Sensitivity: 0.9999, Specificity: 0.9075\n",
      "\n",
      "Fold [3/10] Epoch [8/30], time cost: 68.0025,\n",
      " Train Cross Loss: 0.0726, Train Contras Loss: 0.3574 Train acc:  0.9762,\n",
      " Val Cross loss: 0.0601, Val Contras loss: 0.3280, Val accuracy: 0.9822, Sensitivity: 0.9946, Specificity: 0.9694\n",
      "\n",
      "Fold [3/10] Epoch [9/30], time cost: 68.0869,\n",
      " Train Cross Loss: 0.0665, Train Contras Loss: 0.3245 Train acc:  0.9784,\n",
      " Val Cross loss: 0.0757, Val Contras loss: 0.3918, Val accuracy: 0.9752, Sensitivity: 0.9988, Specificity: 0.9508\n",
      "\n",
      "Fold [3/10] Epoch [10/30], time cost: 68.4115,\n",
      " Train Cross Loss: 0.0630, Train Contras Loss: 0.3042 Train acc:  0.9798,\n",
      " Val Cross loss: 0.0579, Val Contras loss: 0.3227, Val accuracy: 0.9822, Sensitivity: 0.9963, Specificity: 0.9677\n",
      "\n",
      "Fold [3/10] Epoch [11/30], time cost: 68.0526,\n",
      " Train Cross Loss: 0.0591, Train Contras Loss: 0.2771 Train acc:  0.9816,\n",
      " Val Cross loss: 0.0734, Val Contras loss: 0.3304, Val accuracy: 0.9748, Sensitivity: 0.9998, Specificity: 0.9490\n",
      "\n",
      "Fold [3/10] Epoch [12/30], time cost: 67.2023,\n",
      " Train Cross Loss: 0.0567, Train Contras Loss: 0.2635 Train acc:  0.9818,\n",
      " Val Cross loss: 0.0508, Val Contras loss: 0.2732, Val accuracy: 0.9857, Sensitivity: 0.9953, Specificity: 0.9758\n",
      "\n",
      "Fold [3/10] Epoch [13/30], time cost: 68.2087,\n",
      " Train Cross Loss: 0.0533, Train Contras Loss: 0.2466 Train acc:  0.9834,\n",
      " Val Cross loss: 0.0560, Val Contras loss: 0.2785, Val accuracy: 0.9826, Sensitivity: 0.9983, Specificity: 0.9663\n",
      "\n",
      "Fold [3/10] Epoch [14/30], time cost: 67.4544,\n",
      " Train Cross Loss: 0.0513, Train Contras Loss: 0.2319 Train acc:  0.9841,\n",
      " Val Cross loss: 0.1511, Val Contras loss: 0.5691, Val accuracy: 0.9499, Sensitivity: 1.0000, Specificity: 0.8980\n",
      "\n",
      "Fold [3/10] Epoch [15/30], time cost: 67.2108,\n",
      " Train Cross Loss: 0.0507, Train Contras Loss: 0.2252 Train acc:  0.9845,\n",
      " Val Cross loss: 0.0451, Val Contras loss: 0.2352, Val accuracy: 0.9870, Sensitivity: 0.9969, Specificity: 0.9768\n",
      "\n",
      "Fold [3/10] Epoch [16/30], time cost: 67.2006,\n",
      " Train Cross Loss: 0.0475, Train Contras Loss: 0.2109 Train acc:  0.9854,\n",
      " Val Cross loss: 0.0478, Val Contras loss: 0.2486, Val accuracy: 0.9858, Sensitivity: 0.9880, Specificity: 0.9837\n",
      "\n",
      "Fold [3/10] Epoch [17/30], time cost: 67.5829,\n",
      " Train Cross Loss: 0.0463, Train Contras Loss: 0.1999 Train acc:  0.9859,\n",
      " Val Cross loss: 0.0569, Val Contras loss: 0.2760, Val accuracy: 0.9828, Sensitivity: 0.9986, Specificity: 0.9664\n",
      "\n",
      "Fold [3/10] Epoch [18/30], time cost: 67.2999,\n",
      " Train Cross Loss: 0.0441, Train Contras Loss: 0.1921 Train acc:  0.9859,\n",
      " Val Cross loss: 0.0496, Val Contras loss: 0.2506, Val accuracy: 0.9855, Sensitivity: 0.9984, Specificity: 0.9721\n",
      "\n",
      "Fold [3/10] Epoch [19/30], time cost: 67.1604,\n",
      " Train Cross Loss: 0.0424, Train Contras Loss: 0.1795 Train acc:  0.9873,\n",
      " Val Cross loss: 0.0487, Val Contras loss: 0.2502, Val accuracy: 0.9853, Sensitivity: 0.9981, Specificity: 0.9721\n",
      "\n",
      "Fold [3/10] Epoch [20/30], time cost: 67.6371,\n",
      " Train Cross Loss: 0.0419, Train Contras Loss: 0.1821 Train acc:  0.9871,\n",
      " Val Cross loss: 0.0435, Val Contras loss: 0.2247, Val accuracy: 0.9876, Sensitivity: 0.9931, Specificity: 0.9819\n",
      "\n",
      "Fold [3/10] Epoch [21/30], time cost: 66.9894,\n",
      " Train Cross Loss: 0.0417, Train Contras Loss: 0.1750 Train acc:  0.9871,\n",
      " Val Cross loss: 0.0514, Val Contras loss: 0.2713, Val accuracy: 0.9851, Sensitivity: 0.9854, Specificity: 0.9848\n",
      "\n",
      "Fold [3/10] Epoch [22/30], time cost: 67.3871,\n",
      " Train Cross Loss: 0.0385, Train Contras Loss: 0.1614 Train acc:  0.9883,\n",
      " Val Cross loss: 0.0504, Val Contras loss: 0.2578, Val accuracy: 0.9845, Sensitivity: 0.9840, Specificity: 0.9850\n",
      "\n",
      "Fold [3/10] Epoch [23/30], time cost: 67.4750,\n",
      " Train Cross Loss: 0.0353, Train Contras Loss: 0.1493 Train acc:  0.9896,\n",
      " Val Cross loss: 0.0461, Val Contras loss: 0.2302, Val accuracy: 0.9864, Sensitivity: 0.9988, Specificity: 0.9735\n",
      "\n",
      "Fold [3/10] Epoch [24/30], time cost: 68.4610,\n",
      " Train Cross Loss: 0.0383, Train Contras Loss: 0.1504 Train acc:  0.9888,\n",
      " Val Cross loss: 0.0537, Val Contras loss: 0.2553, Val accuracy: 0.9851, Sensitivity: 0.9970, Specificity: 0.9729\n",
      "\n",
      "Fold [3/10] Epoch [25/30], time cost: 66.9583,\n",
      " Train Cross Loss: 0.0353, Train Contras Loss: 0.1425 Train acc:  0.9891,\n",
      " Val Cross loss: 0.0450, Val Contras loss: 0.2593, Val accuracy: 0.9866, Sensitivity: 0.9967, Specificity: 0.9762\n",
      "\n",
      "Fold [3/10] Epoch [26/30], time cost: 66.8001,\n",
      " Train Cross Loss: 0.0355, Train Contras Loss: 0.1412 Train acc:  0.9889,\n",
      " Val Cross loss: 0.0562, Val Contras loss: 0.2415, Val accuracy: 0.9823, Sensitivity: 0.9756, Specificity: 0.9893\n",
      "\n",
      "Fold [3/10] Epoch [27/30], time cost: 67.3187,\n",
      " Train Cross Loss: 0.0337, Train Contras Loss: 0.1362 Train acc:  0.9895,\n",
      " Val Cross loss: 0.0483, Val Contras loss: 0.2614, Val accuracy: 0.9857, Sensitivity: 0.9846, Specificity: 0.9868\n",
      "\n",
      "Fold [3/10] Epoch [28/30], time cost: 67.0509,\n",
      " Train Cross Loss: 0.0320, Train Contras Loss: 0.1286 Train acc:  0.9900,\n",
      " Val Cross loss: 0.0706, Val Contras loss: 0.3288, Val accuracy: 0.9756, Sensitivity: 0.9634, Specificity: 0.9882\n",
      "\n",
      "Fold [3/10] Epoch [29/30], time cost: 67.8979,\n",
      " Train Cross Loss: 0.0319, Train Contras Loss: 0.1268 Train acc:  0.9905,\n",
      " Val Cross loss: 0.0388, Val Contras loss: 0.2068, Val accuracy: 0.9886, Sensitivity: 0.9931, Specificity: 0.9840\n",
      "\n",
      "Fold [3/10] Epoch [30/30], time cost: 67.2594,\n",
      " Train Cross Loss: 0.0327, Train Contras Loss: 0.1270 Train acc:  0.9901,\n",
      " Val Cross loss: 0.0415, Val Contras loss: 0.2264, Val accuracy: 0.9887, Sensitivity: 0.9954, Specificity: 0.9818\n",
      "['C4-P4', 'CZ-PZ', 'P4-O2', 'P8-O2', 'P7-O1', 'P3-O1']\n",
      "\n",
      "***********\n",
      "Best epoch: 29 Acc: 0.9887377914855834 Sensitivity for pre-ictal: 0.9954039893372553 Specificity: 0.9818441064638783\n",
      "***********\n",
      "\n",
      "Test Loss: 0.0435, Test accuracy: 0.9869, Sensitivity: 0.9937, Specificity: 0.9800\n",
      "\n",
      "Fold [4/10] Epoch [1/30], time cost: 68.7033,\n",
      " Train Cross Loss: 0.2366, Train Contras Loss: 1.3330 Train acc:  0.9036,\n",
      " Val Cross loss: 0.1523, Val Contras loss: 0.8795, Val accuracy: 0.9413, Sensitivity: 0.9225, Specificity: 0.9608\n",
      "\n",
      "Fold [4/10] Epoch [2/30], time cost: 67.2849,\n",
      " Train Cross Loss: 0.1464, Train Contras Loss: 0.8235 Train acc:  0.9458,\n",
      " Val Cross loss: 0.1158, Val Contras loss: 0.7140, Val accuracy: 0.9599, Sensitivity: 0.9801, Specificity: 0.9390\n",
      "\n",
      "Fold [4/10] Epoch [3/30], time cost: 67.3489,\n",
      " Train Cross Loss: 0.1265, Train Contras Loss: 0.6774 Train acc:  0.9550,\n",
      " Val Cross loss: 0.1154, Val Contras loss: 0.7258, Val accuracy: 0.9567, Sensitivity: 0.9820, Specificity: 0.9305\n",
      "\n",
      "Fold [4/10] Epoch [4/30], time cost: 67.1179,\n",
      " Train Cross Loss: 0.1107, Train Contras Loss: 0.5874 Train acc:  0.9612,\n",
      " Val Cross loss: 0.0919, Val Contras loss: 0.5604, Val accuracy: 0.9684, Sensitivity: 0.9737, Specificity: 0.9628\n",
      "\n",
      "Fold [4/10] Epoch [5/30], time cost: 67.8700,\n",
      " Train Cross Loss: 0.0994, Train Contras Loss: 0.5166 Train acc:  0.9658,\n",
      " Val Cross loss: 0.0903, Val Contras loss: 0.4905, Val accuracy: 0.9684, Sensitivity: 0.9936, Specificity: 0.9423\n",
      "\n",
      "Fold [4/10] Epoch [6/30], time cost: 66.8341,\n",
      " Train Cross Loss: 0.0920, Train Contras Loss: 0.4671 Train acc:  0.9689,\n",
      " Val Cross loss: 0.0849, Val Contras loss: 0.4726, Val accuracy: 0.9707, Sensitivity: 0.9972, Specificity: 0.9433\n",
      "\n",
      "Fold [4/10] Epoch [7/30], time cost: 64.8343,\n",
      " Train Cross Loss: 0.0868, Train Contras Loss: 0.4362 Train acc:  0.9711,\n",
      " Val Cross loss: 0.0760, Val Contras loss: 0.4728, Val accuracy: 0.9764, Sensitivity: 0.9876, Specificity: 0.9647\n",
      "\n",
      "Fold [4/10] Epoch [8/30], time cost: 67.8944,\n",
      " Train Cross Loss: 0.0792, Train Contras Loss: 0.4011 Train acc:  0.9742,\n",
      " Val Cross loss: 0.0730, Val Contras loss: 0.4120, Val accuracy: 0.9754, Sensitivity: 0.9771, Specificity: 0.9736\n",
      "\n",
      "Fold [4/10] Epoch [9/30], time cost: 68.2912,\n",
      " Train Cross Loss: 0.0771, Train Contras Loss: 0.3744 Train acc:  0.9745,\n",
      " Val Cross loss: 0.0732, Val Contras loss: 0.3991, Val accuracy: 0.9758, Sensitivity: 0.9959, Specificity: 0.9551\n",
      "\n",
      "Fold [4/10] Epoch [10/30], time cost: 67.9429,\n",
      " Train Cross Loss: 0.0729, Train Contras Loss: 0.3520 Train acc:  0.9765,\n",
      " Val Cross loss: 0.1020, Val Contras loss: 0.4999, Val accuracy: 0.9643, Sensitivity: 0.9989, Specificity: 0.9285\n",
      "\n",
      "Fold [4/10] Epoch [11/30], time cost: 67.1309,\n",
      " Train Cross Loss: 0.0693, Train Contras Loss: 0.3303 Train acc:  0.9782,\n",
      " Val Cross loss: 0.0624, Val Contras loss: 0.3364, Val accuracy: 0.9806, Sensitivity: 0.9877, Specificity: 0.9733\n",
      "\n",
      "Fold [4/10] Epoch [12/30], time cost: 67.6713,\n",
      " Train Cross Loss: 0.0642, Train Contras Loss: 0.3001 Train acc:  0.9799,\n",
      " Val Cross loss: 0.0646, Val Contras loss: 0.3538, Val accuracy: 0.9798, Sensitivity: 0.9955, Specificity: 0.9635\n",
      "\n",
      "Fold [4/10] Epoch [13/30], time cost: 67.6559,\n",
      " Train Cross Loss: 0.0642, Train Contras Loss: 0.2939 Train acc:  0.9798,\n",
      " Val Cross loss: 0.1152, Val Contras loss: 0.4793, Val accuracy: 0.9593, Sensitivity: 0.9997, Specificity: 0.9174\n",
      "\n",
      "Fold [4/10] Epoch [14/30], time cost: 68.4940,\n",
      " Train Cross Loss: 0.0598, Train Contras Loss: 0.2756 Train acc:  0.9816,\n",
      " Val Cross loss: 0.0897, Val Contras loss: 0.3902, Val accuracy: 0.9688, Sensitivity: 0.9513, Specificity: 0.9869\n",
      "\n",
      "Fold [4/10] Epoch [15/30], time cost: 66.8223,\n",
      " Train Cross Loss: 0.0585, Train Contras Loss: 0.2638 Train acc:  0.9820,\n",
      " Val Cross loss: 0.0625, Val Contras loss: 0.3097, Val accuracy: 0.9803, Sensitivity: 0.9990, Specificity: 0.9609\n",
      "\n",
      "Fold [4/10] Epoch [16/30], time cost: 66.5955,\n",
      " Train Cross Loss: 0.0553, Train Contras Loss: 0.2481 Train acc:  0.9830,\n",
      " Val Cross loss: 0.0521, Val Contras loss: 0.2896, Val accuracy: 0.9836, Sensitivity: 0.9893, Specificity: 0.9775\n",
      "\n",
      "Fold [4/10] Epoch [17/30], time cost: 68.0395,\n",
      " Train Cross Loss: 0.0540, Train Contras Loss: 0.2376 Train acc:  0.9834,\n",
      " Val Cross loss: 0.0534, Val Contras loss: 0.2883, Val accuracy: 0.9835, Sensitivity: 0.9966, Specificity: 0.9698\n",
      "\n",
      "Fold [4/10] Epoch [18/30], time cost: 67.7285,\n",
      " Train Cross Loss: 0.0526, Train Contras Loss: 0.2345 Train acc:  0.9837,\n",
      " Val Cross loss: 0.0498, Val Contras loss: 0.2754, Val accuracy: 0.9842, Sensitivity: 0.9916, Specificity: 0.9765\n",
      "\n",
      "Fold [4/10] Epoch [19/30], time cost: 67.2126,\n",
      " Train Cross Loss: 0.0518, Train Contras Loss: 0.2240 Train acc:  0.9840,\n",
      " Val Cross loss: 0.0697, Val Contras loss: 0.3494, Val accuracy: 0.9764, Sensitivity: 0.9675, Specificity: 0.9855\n",
      "\n",
      "Fold [4/10] Epoch [20/30], time cost: 66.5157,\n",
      " Train Cross Loss: 0.0480, Train Contras Loss: 0.2095 Train acc:  0.9856,\n",
      " Val Cross loss: 0.0664, Val Contras loss: 0.3596, Val accuracy: 0.9778, Sensitivity: 0.9727, Specificity: 0.9830\n",
      "\n",
      "Fold [4/10] Epoch [21/30], time cost: 67.5250,\n",
      " Train Cross Loss: 0.0477, Train Contras Loss: 0.2058 Train acc:  0.9852,\n",
      " Val Cross loss: 0.0547, Val Contras loss: 0.2947, Val accuracy: 0.9820, Sensitivity: 0.9960, Specificity: 0.9675\n",
      "\n",
      "Fold [4/10] Epoch [22/30], time cost: 67.3096,\n",
      " Train Cross Loss: 0.0445, Train Contras Loss: 0.1954 Train acc:  0.9865,\n",
      " Val Cross loss: 0.0572, Val Contras loss: 0.2875, Val accuracy: 0.9814, Sensitivity: 0.9971, Specificity: 0.9651\n",
      "\n",
      "Fold [4/10] Epoch [23/30], time cost: 67.3503,\n",
      " Train Cross Loss: 0.0445, Train Contras Loss: 0.1931 Train acc:  0.9864,\n",
      " Val Cross loss: 0.0637, Val Contras loss: 0.3090, Val accuracy: 0.9799, Sensitivity: 0.9991, Specificity: 0.9600\n",
      "\n",
      "Fold [4/10] Epoch [24/30], time cost: 66.4867,\n",
      " Train Cross Loss: 0.0446, Train Contras Loss: 0.1923 Train acc:  0.9865,\n",
      " Val Cross loss: 0.0512, Val Contras loss: 0.2752, Val accuracy: 0.9838, Sensitivity: 0.9966, Specificity: 0.9706\n",
      "\n",
      "Fold [4/10] Epoch [25/30], time cost: 66.6386,\n",
      " Train Cross Loss: 0.0417, Train Contras Loss: 0.1782 Train acc:  0.9874,\n",
      " Val Cross loss: 0.0480, Val Contras loss: 0.2503, Val accuracy: 0.9855, Sensitivity: 0.9975, Specificity: 0.9731\n",
      "\n",
      "Fold [4/10] Epoch [26/30], time cost: 68.0529,\n",
      " Train Cross Loss: 0.0427, Train Contras Loss: 0.1796 Train acc:  0.9867,\n",
      " Val Cross loss: 0.0636, Val Contras loss: 0.3315, Val accuracy: 0.9788, Sensitivity: 0.9756, Specificity: 0.9821\n",
      "\n",
      "Fold [4/10] Epoch [27/30], time cost: 67.4538,\n",
      " Train Cross Loss: 0.0396, Train Contras Loss: 0.1715 Train acc:  0.9884,\n",
      " Val Cross loss: 0.0587, Val Contras loss: 0.2735, Val accuracy: 0.9816, Sensitivity: 0.9991, Specificity: 0.9635\n",
      "\n",
      "Fold [4/10] Epoch [28/30], time cost: 66.9988,\n",
      " Train Cross Loss: 0.0401, Train Contras Loss: 0.1659 Train acc:  0.9880,\n",
      " Val Cross loss: 0.0451, Val Contras loss: 0.2290, Val accuracy: 0.9866, Sensitivity: 0.9986, Specificity: 0.9741\n",
      "\n",
      "Fold [4/10] Epoch [29/30], time cost: 67.7301,\n",
      " Train Cross Loss: 0.0383, Train Contras Loss: 0.1646 Train acc:  0.9885,\n",
      " Val Cross loss: 0.0482, Val Contras loss: 0.2539, Val accuracy: 0.9843, Sensitivity: 0.9940, Specificity: 0.9743\n",
      "\n",
      "Fold [4/10] Epoch [30/30], time cost: 67.9763,\n",
      " Train Cross Loss: 0.0389, Train Contras Loss: 0.1607 Train acc:  0.9882,\n",
      " Val Cross loss: 0.0477, Val Contras loss: 0.2601, Val accuracy: 0.9855, Sensitivity: 0.9882, Specificity: 0.9828\n",
      "['C4-P4', 'CZ-PZ', 'P4-O2', 'P8-O2', 'P7-O1', 'P3-O1']\n",
      "\n",
      "***********\n",
      "Best epoch: 27 Acc: 0.9865881583251553 Sensitivity for pre-ictal: 0.9986223365172667 Specificity: 0.9741223480163638\n",
      "***********\n",
      "\n",
      "Test Loss: 0.0439, Test accuracy: 0.9867, Sensitivity: 0.9982, Specificity: 0.9750\n",
      "\n",
      "Fold [5/10] Epoch [1/30], time cost: 71.3183,\n",
      " Train Cross Loss: 0.2323, Train Contras Loss: 1.3179 Train acc:  0.9050,\n",
      " Val Cross loss: 0.1292, Val Contras loss: 0.7912, Val accuracy: 0.9528, Sensitivity: 0.9515, Specificity: 0.9541\n",
      "\n",
      "Fold [5/10] Epoch [2/30], time cost: 66.6538,\n",
      " Train Cross Loss: 0.1415, Train Contras Loss: 0.7861 Train acc:  0.9483,\n",
      " Val Cross loss: 0.1396, Val Contras loss: 0.7998, Val accuracy: 0.9458, Sensitivity: 0.9217, Specificity: 0.9700\n",
      "\n",
      "Fold [5/10] Epoch [3/30], time cost: 68.0359,\n",
      " Train Cross Loss: 0.1173, Train Contras Loss: 0.6412 Train acc:  0.9585,\n",
      " Val Cross loss: 0.1271, Val Contras loss: 0.7691, Val accuracy: 0.9490, Sensitivity: 0.9262, Specificity: 0.9719\n",
      "\n",
      "Fold [5/10] Epoch [4/30], time cost: 68.1261,\n",
      " Train Cross Loss: 0.1022, Train Contras Loss: 0.5503 Train acc:  0.9636,\n",
      " Val Cross loss: 0.0845, Val Contras loss: 0.4741, Val accuracy: 0.9720, Sensitivity: 0.9897, Specificity: 0.9541\n",
      "\n",
      "Fold [5/10] Epoch [5/30], time cost: 67.3885,\n",
      " Train Cross Loss: 0.0932, Train Contras Loss: 0.4877 Train acc:  0.9676,\n",
      " Val Cross loss: 0.1012, Val Contras loss: 0.5082, Val accuracy: 0.9654, Sensitivity: 0.9989, Specificity: 0.9318\n",
      "\n",
      "Fold [5/10] Epoch [6/30], time cost: 66.8232,\n",
      " Train Cross Loss: 0.0850, Train Contras Loss: 0.4324 Train acc:  0.9707,\n",
      " Val Cross loss: 0.0825, Val Contras loss: 0.4049, Val accuracy: 0.9724, Sensitivity: 0.9982, Specificity: 0.9465\n",
      "\n",
      "Fold [5/10] Epoch [7/30], time cost: 67.5927,\n",
      " Train Cross Loss: 0.0777, Train Contras Loss: 0.3925 Train acc:  0.9742,\n",
      " Val Cross loss: 0.1022, Val Contras loss: 0.4636, Val accuracy: 0.9638, Sensitivity: 0.9992, Specificity: 0.9283\n",
      "\n",
      "Fold [5/10] Epoch [8/30], time cost: 67.6844,\n",
      " Train Cross Loss: 0.0713, Train Contras Loss: 0.3487 Train acc:  0.9766,\n",
      " Val Cross loss: 0.0650, Val Contras loss: 0.3185, Val accuracy: 0.9795, Sensitivity: 0.9987, Specificity: 0.9603\n",
      "\n",
      "Fold [5/10] Epoch [9/30], time cost: 66.6660,\n",
      " Train Cross Loss: 0.0645, Train Contras Loss: 0.3171 Train acc:  0.9799,\n",
      " Val Cross loss: 0.0678, Val Contras loss: 0.3413, Val accuracy: 0.9780, Sensitivity: 0.9983, Specificity: 0.9577\n",
      "\n",
      "Fold [5/10] Epoch [10/30], time cost: 67.0676,\n",
      " Train Cross Loss: 0.0633, Train Contras Loss: 0.3022 Train acc:  0.9799,\n",
      " Val Cross loss: 0.0595, Val Contras loss: 0.3196, Val accuracy: 0.9823, Sensitivity: 0.9952, Specificity: 0.9694\n",
      "\n",
      "Fold [5/10] Epoch [11/30], time cost: 67.1751,\n",
      " Train Cross Loss: 0.0595, Train Contras Loss: 0.2776 Train acc:  0.9810,\n",
      " Val Cross loss: 0.0565, Val Contras loss: 0.2962, Val accuracy: 0.9824, Sensitivity: 0.9849, Specificity: 0.9800\n",
      "\n",
      "Fold [5/10] Epoch [12/30], time cost: 67.9860,\n",
      " Train Cross Loss: 0.0576, Train Contras Loss: 0.2676 Train acc:  0.9821,\n",
      " Val Cross loss: 0.0636, Val Contras loss: 0.3251, Val accuracy: 0.9812, Sensitivity: 0.9954, Specificity: 0.9669\n",
      "\n",
      "Fold [5/10] Epoch [13/30], time cost: 67.0715,\n",
      " Train Cross Loss: 0.0536, Train Contras Loss: 0.2429 Train acc:  0.9836,\n",
      " Val Cross loss: 0.0535, Val Contras loss: 0.2718, Val accuracy: 0.9840, Sensitivity: 0.9936, Specificity: 0.9743\n",
      "\n",
      "Fold [5/10] Epoch [14/30], time cost: 66.3431,\n",
      " Train Cross Loss: 0.0506, Train Contras Loss: 0.2330 Train acc:  0.9845,\n",
      " Val Cross loss: 0.0594, Val Contras loss: 0.2988, Val accuracy: 0.9821, Sensitivity: 0.9975, Specificity: 0.9666\n",
      "\n",
      "Fold [5/10] Epoch [15/30], time cost: 66.7792,\n",
      " Train Cross Loss: 0.0489, Train Contras Loss: 0.2214 Train acc:  0.9850,\n",
      " Val Cross loss: 0.0484, Val Contras loss: 0.2419, Val accuracy: 0.9865, Sensitivity: 0.9899, Specificity: 0.9831\n",
      "\n",
      "Fold [5/10] Epoch [16/30], time cost: 67.8799,\n",
      " Train Cross Loss: 0.0481, Train Contras Loss: 0.2140 Train acc:  0.9853,\n",
      " Val Cross loss: 0.0444, Val Contras loss: 0.2152, Val accuracy: 0.9878, Sensitivity: 0.9954, Specificity: 0.9801\n",
      "\n",
      "Fold [5/10] Epoch [17/30], time cost: 66.9694,\n",
      " Train Cross Loss: 0.0467, Train Contras Loss: 0.2064 Train acc:  0.9858,\n",
      " Val Cross loss: 0.0649, Val Contras loss: 0.2820, Val accuracy: 0.9806, Sensitivity: 0.9996, Specificity: 0.9615\n",
      "\n",
      "Fold [5/10] Epoch [18/30], time cost: 67.2356,\n",
      " Train Cross Loss: 0.0436, Train Contras Loss: 0.1913 Train acc:  0.9868,\n",
      " Val Cross loss: 0.0584, Val Contras loss: 0.2718, Val accuracy: 0.9835, Sensitivity: 0.9991, Specificity: 0.9678\n",
      "\n",
      "Fold [5/10] Epoch [19/30], time cost: 67.9732,\n",
      " Train Cross Loss: 0.0422, Train Contras Loss: 0.1848 Train acc:  0.9873,\n",
      " Val Cross loss: 0.0459, Val Contras loss: 0.2303, Val accuracy: 0.9873, Sensitivity: 0.9951, Specificity: 0.9796\n",
      "\n",
      "Fold [5/10] Epoch [20/30], time cost: 68.2297,\n",
      " Train Cross Loss: 0.0403, Train Contras Loss: 0.1718 Train acc:  0.9879,\n",
      " Val Cross loss: 0.0508, Val Contras loss: 0.2301, Val accuracy: 0.9866, Sensitivity: 0.9984, Specificity: 0.9748\n",
      "\n",
      "Fold [5/10] Epoch [21/30], time cost: 66.9631,\n",
      " Train Cross Loss: 0.0408, Train Contras Loss: 0.1716 Train acc:  0.9877,\n",
      " Val Cross loss: 0.0657, Val Contras loss: 0.2714, Val accuracy: 0.9812, Sensitivity: 0.9999, Specificity: 0.9624\n",
      "\n",
      "Fold [5/10] Epoch [22/30], time cost: 68.7933,\n",
      " Train Cross Loss: 0.0369, Train Contras Loss: 0.1589 Train acc:  0.9891,\n",
      " Val Cross loss: 0.0463, Val Contras loss: 0.2306, Val accuracy: 0.9862, Sensitivity: 0.9979, Specificity: 0.9745\n",
      "\n",
      "Fold [5/10] Epoch [23/30], time cost: 68.9578,\n",
      " Train Cross Loss: 0.0357, Train Contras Loss: 0.1494 Train acc:  0.9897,\n",
      " Val Cross loss: 0.1076, Val Contras loss: 0.3915, Val accuracy: 0.9675, Sensitivity: 1.0000, Specificity: 0.9348\n",
      "\n",
      "Fold [5/10] Epoch [24/30], time cost: 71.2886,\n",
      " Train Cross Loss: 0.0348, Train Contras Loss: 0.1483 Train acc:  0.9896,\n",
      " Val Cross loss: 0.1017, Val Contras loss: 0.4041, Val accuracy: 0.9683, Sensitivity: 1.0000, Specificity: 0.9364\n",
      "\n",
      "Fold [5/10] Epoch [25/30], time cost: 68.3432,\n",
      " Train Cross Loss: 0.0353, Train Contras Loss: 0.1470 Train acc:  0.9894,\n",
      " Val Cross loss: 0.0410, Val Contras loss: 0.2049, Val accuracy: 0.9887, Sensitivity: 0.9927, Specificity: 0.9846\n",
      "\n",
      "Fold [5/10] Epoch [26/30], time cost: 67.7599,\n",
      " Train Cross Loss: 0.0337, Train Contras Loss: 0.1375 Train acc:  0.9903,\n",
      " Val Cross loss: 0.0416, Val Contras loss: 0.1910, Val accuracy: 0.9882, Sensitivity: 0.9883, Specificity: 0.9881\n",
      "\n",
      "Fold [5/10] Epoch [27/30], time cost: 68.3312,\n",
      " Train Cross Loss: 0.0337, Train Contras Loss: 0.1367 Train acc:  0.9901,\n",
      " Val Cross loss: 0.0614, Val Contras loss: 0.2623, Val accuracy: 0.9806, Sensitivity: 1.0000, Specificity: 0.9610\n",
      "\n",
      "Fold [5/10] Epoch [28/30], time cost: 72.2290,\n",
      " Train Cross Loss: 0.0327, Train Contras Loss: 0.1328 Train acc:  0.9904,\n",
      " Val Cross loss: 0.0430, Val Contras loss: 0.2137, Val accuracy: 0.9875, Sensitivity: 0.9885, Specificity: 0.9864\n",
      "\n",
      "Fold [5/10] Epoch [29/30], time cost: 72.5825,\n",
      " Train Cross Loss: 0.0318, Train Contras Loss: 0.1282 Train acc:  0.9905,\n",
      " Val Cross loss: 0.0527, Val Contras loss: 0.2617, Val accuracy: 0.9823, Sensitivity: 0.9758, Specificity: 0.9888\n",
      "\n",
      "Fold [5/10] Epoch [30/30], time cost: 70.8697,\n",
      " Train Cross Loss: 0.0305, Train Contras Loss: 0.1219 Train acc:  0.9907,\n",
      " Val Cross loss: 0.0417, Val Contras loss: 0.2048, Val accuracy: 0.9892, Sensitivity: 0.9960, Specificity: 0.9824\n",
      "['C4-P4', 'CZ-PZ', 'P4-O2', 'P8-O2', 'P7-O1', 'P3-O1']\n",
      "\n",
      "***********\n",
      "Best epoch: 29 Acc: 0.9892051030421982 Sensitivity for pre-ictal: 0.9959903021260723 Specificity: 0.9823887587822014\n",
      "***********\n",
      "\n",
      "Test Loss: 0.0427, Test accuracy: 0.9867, Sensitivity: 0.9952, Specificity: 0.9781\n",
      "\n",
      "Fold [6/10] Epoch [1/30], time cost: 71.0068,\n",
      " Train Cross Loss: 0.2295, Train Contras Loss: 1.3004 Train acc:  0.9055,\n",
      " Val Cross loss: 0.1893, Val Contras loss: 0.9595, Val accuracy: 0.9297, Sensitivity: 0.8916, Specificity: 0.9682\n",
      "\n",
      "Fold [6/10] Epoch [2/30], time cost: 71.7433,\n",
      " Train Cross Loss: 0.1422, Train Contras Loss: 0.7911 Train acc:  0.9472,\n",
      " Val Cross loss: 0.1349, Val Contras loss: 0.8290, Val accuracy: 0.9471, Sensitivity: 0.9261, Specificity: 0.9683\n",
      "\n",
      "Fold [6/10] Epoch [3/30], time cost: 70.8982,\n",
      " Train Cross Loss: 0.1217, Train Contras Loss: 0.6679 Train acc:  0.9561,\n",
      " Val Cross loss: 0.1041, Val Contras loss: 0.5433, Val accuracy: 0.9621, Sensitivity: 0.9952, Specificity: 0.9285\n",
      "\n",
      "Fold [6/10] Epoch [4/30], time cost: 71.0566,\n",
      " Train Cross Loss: 0.1053, Train Contras Loss: 0.5694 Train acc:  0.9624,\n",
      " Val Cross loss: 0.1163, Val Contras loss: 0.5516, Val accuracy: 0.9599, Sensitivity: 0.9989, Specificity: 0.9203\n",
      "\n",
      "Fold [6/10] Epoch [5/30], time cost: 69.5893,\n",
      " Train Cross Loss: 0.0970, Train Contras Loss: 0.5106 Train acc:  0.9664,\n",
      " Val Cross loss: 0.0878, Val Contras loss: 0.4983, Val accuracy: 0.9697, Sensitivity: 0.9922, Specificity: 0.9469\n",
      "\n",
      "Fold [6/10] Epoch [6/30], time cost: 68.4600,\n",
      " Train Cross Loss: 0.0888, Train Contras Loss: 0.4623 Train acc:  0.9699,\n",
      " Val Cross loss: 0.0784, Val Contras loss: 0.4280, Val accuracy: 0.9767, Sensitivity: 0.9830, Specificity: 0.9704\n",
      "\n",
      "Fold [6/10] Epoch [7/30], time cost: 69.6399,\n",
      " Train Cross Loss: 0.0822, Train Contras Loss: 0.4156 Train acc:  0.9728,\n",
      " Val Cross loss: 0.0748, Val Contras loss: 0.4065, Val accuracy: 0.9763, Sensitivity: 0.9821, Specificity: 0.9704\n",
      "\n",
      "Fold [6/10] Epoch [8/30], time cost: 67.1213,\n",
      " Train Cross Loss: 0.0771, Train Contras Loss: 0.3869 Train acc:  0.9744,\n",
      " Val Cross loss: 0.0898, Val Contras loss: 0.4192, Val accuracy: 0.9682, Sensitivity: 0.9994, Specificity: 0.9366\n",
      "\n",
      "Fold [6/10] Epoch [9/30], time cost: 67.7445,\n",
      " Train Cross Loss: 0.0703, Train Contras Loss: 0.3547 Train acc:  0.9768,\n",
      " Val Cross loss: 0.1076, Val Contras loss: 0.4870, Val accuracy: 0.9620, Sensitivity: 0.9407, Specificity: 0.9835\n",
      "\n",
      "Fold [6/10] Epoch [10/30], time cost: 67.1656,\n",
      " Train Cross Loss: 0.0664, Train Contras Loss: 0.3289 Train acc:  0.9781,\n",
      " Val Cross loss: 0.0695, Val Contras loss: 0.3649, Val accuracy: 0.9773, Sensitivity: 0.9954, Specificity: 0.9590\n",
      "\n",
      "Fold [6/10] Epoch [11/30], time cost: 66.6793,\n",
      " Train Cross Loss: 0.0633, Train Contras Loss: 0.3045 Train acc:  0.9795,\n",
      " Val Cross loss: 0.0608, Val Contras loss: 0.3421, Val accuracy: 0.9808, Sensitivity: 0.9838, Specificity: 0.9778\n",
      "\n",
      "Fold [6/10] Epoch [12/30], time cost: 67.2755,\n",
      " Train Cross Loss: 0.0589, Train Contras Loss: 0.2788 Train acc:  0.9816,\n",
      " Val Cross loss: 0.0646, Val Contras loss: 0.3377, Val accuracy: 0.9801, Sensitivity: 0.9973, Specificity: 0.9627\n",
      "\n",
      "Fold [6/10] Epoch [13/30], time cost: 69.7619,\n",
      " Train Cross Loss: 0.0593, Train Contras Loss: 0.2795 Train acc:  0.9812,\n",
      " Val Cross loss: 0.0664, Val Contras loss: 0.3512, Val accuracy: 0.9790, Sensitivity: 0.9950, Specificity: 0.9629\n",
      "\n",
      "Fold [6/10] Epoch [14/30], time cost: 67.7919,\n",
      " Train Cross Loss: 0.0544, Train Contras Loss: 0.2578 Train acc:  0.9827,\n",
      " Val Cross loss: 0.0699, Val Contras loss: 0.3293, Val accuracy: 0.9767, Sensitivity: 0.9996, Specificity: 0.9535\n",
      "\n",
      "Fold [6/10] Epoch [15/30], time cost: 68.3263,\n",
      " Train Cross Loss: 0.0533, Train Contras Loss: 0.2477 Train acc:  0.9835,\n",
      " Val Cross loss: 0.0565, Val Contras loss: 0.3057, Val accuracy: 0.9821, Sensitivity: 0.9961, Specificity: 0.9680\n",
      "\n",
      "Fold [6/10] Epoch [16/30], time cost: 67.8476,\n",
      " Train Cross Loss: 0.0527, Train Contras Loss: 0.2414 Train acc:  0.9832,\n",
      " Val Cross loss: 0.0643, Val Contras loss: 0.3166, Val accuracy: 0.9795, Sensitivity: 0.9993, Specificity: 0.9596\n",
      "\n",
      "Fold [6/10] Epoch [17/30], time cost: 69.1394,\n",
      " Train Cross Loss: 0.0493, Train Contras Loss: 0.2252 Train acc:  0.9849,\n",
      " Val Cross loss: 0.0791, Val Contras loss: 0.3548, Val accuracy: 0.9746, Sensitivity: 0.9997, Specificity: 0.9491\n",
      "\n",
      "Fold [6/10] Epoch [18/30], time cost: 69.6337,\n",
      " Train Cross Loss: 0.0464, Train Contras Loss: 0.2094 Train acc:  0.9857,\n",
      " Val Cross loss: 0.0513, Val Contras loss: 0.2712, Val accuracy: 0.9847, Sensitivity: 0.9954, Specificity: 0.9739\n",
      "\n",
      "Fold [6/10] Epoch [19/30], time cost: 68.7229,\n",
      " Train Cross Loss: 0.0461, Train Contras Loss: 0.2070 Train acc:  0.9860,\n",
      " Val Cross loss: 0.0591, Val Contras loss: 0.3031, Val accuracy: 0.9814, Sensitivity: 0.9985, Specificity: 0.9640\n",
      "\n",
      "Fold [6/10] Epoch [20/30], time cost: 68.3529,\n",
      " Train Cross Loss: 0.0454, Train Contras Loss: 0.2008 Train acc:  0.9859,\n",
      " Val Cross loss: 0.0572, Val Contras loss: 0.3227, Val accuracy: 0.9833, Sensitivity: 0.9920, Specificity: 0.9745\n",
      "\n",
      "Fold [6/10] Epoch [21/30], time cost: 67.2621,\n",
      " Train Cross Loss: 0.0434, Train Contras Loss: 0.1889 Train acc:  0.9867,\n",
      " Val Cross loss: 0.0544, Val Contras loss: 0.2883, Val accuracy: 0.9837, Sensitivity: 0.9928, Specificity: 0.9745\n",
      "\n",
      "Fold [6/10] Epoch [22/30], time cost: 67.3040,\n",
      " Train Cross Loss: 0.0427, Train Contras Loss: 0.1898 Train acc:  0.9875,\n",
      " Val Cross loss: 0.0538, Val Contras loss: 0.2746, Val accuracy: 0.9835, Sensitivity: 0.9958, Specificity: 0.9710\n",
      "\n",
      "Fold [6/10] Epoch [23/30], time cost: 68.0497,\n",
      " Train Cross Loss: 0.0399, Train Contras Loss: 0.1747 Train acc:  0.9877,\n",
      " Val Cross loss: 0.0629, Val Contras loss: 0.3170, Val accuracy: 0.9811, Sensitivity: 0.9763, Specificity: 0.9859\n",
      "\n",
      "Fold [6/10] Epoch [24/30], time cost: 68.0232,\n",
      " Train Cross Loss: 0.0409, Train Contras Loss: 0.1754 Train acc:  0.9876,\n",
      " Val Cross loss: 0.0600, Val Contras loss: 0.2831, Val accuracy: 0.9822, Sensitivity: 0.9986, Specificity: 0.9657\n",
      "\n",
      "Fold [6/10] Epoch [25/30], time cost: 67.4796,\n",
      " Train Cross Loss: 0.0397, Train Contras Loss: 0.1671 Train acc:  0.9880,\n",
      " Val Cross loss: 0.0576, Val Contras loss: 0.2676, Val accuracy: 0.9834, Sensitivity: 0.9994, Specificity: 0.9671\n",
      "\n",
      "Fold [6/10] Epoch [26/30], time cost: 67.7455,\n",
      " Train Cross Loss: 0.0386, Train Contras Loss: 0.1630 Train acc:  0.9885,\n",
      " Val Cross loss: 0.0490, Val Contras loss: 0.2619, Val accuracy: 0.9856, Sensitivity: 0.9960, Specificity: 0.9751\n",
      "\n",
      "Fold [6/10] Epoch [27/30], time cost: 67.6829,\n",
      " Train Cross Loss: 0.0359, Train Contras Loss: 0.1556 Train acc:  0.9892,\n",
      " Val Cross loss: 0.0434, Val Contras loss: 0.2189, Val accuracy: 0.9878, Sensitivity: 0.9943, Specificity: 0.9813\n",
      "\n",
      "Fold [6/10] Epoch [28/30], time cost: 68.1878,\n",
      " Train Cross Loss: 0.0343, Train Contras Loss: 0.1505 Train acc:  0.9896,\n",
      " Val Cross loss: 0.0806, Val Contras loss: 0.3589, Val accuracy: 0.9744, Sensitivity: 0.9993, Specificity: 0.9493\n",
      "\n",
      "Fold [6/10] Epoch [29/30], time cost: 66.9905,\n",
      " Train Cross Loss: 0.0353, Train Contras Loss: 0.1476 Train acc:  0.9891,\n",
      " Val Cross loss: 0.0470, Val Contras loss: 0.2485, Val accuracy: 0.9855, Sensitivity: 0.9953, Specificity: 0.9756\n",
      "\n",
      "Fold [6/10] Epoch [30/30], time cost: 66.8114,\n",
      " Train Cross Loss: 0.0340, Train Contras Loss: 0.1398 Train acc:  0.9899,\n",
      " Val Cross loss: 0.0449, Val Contras loss: 0.2381, Val accuracy: 0.9865, Sensitivity: 0.9929, Specificity: 0.9801\n",
      "['C4-P4', 'CZ-PZ', 'P4-O2', 'P8-O2', 'P7-O1', 'P3-O1']\n",
      "\n",
      "***********\n",
      "Best epoch: 26 Acc: 0.9878498995280153 Sensitivity for pre-ictal: 0.9943340144900613 Specificity: 0.9812846797705257\n",
      "***********\n",
      "\n",
      "Test Loss: 0.0358, Test accuracy: 0.9891, Sensitivity: 0.9955, Specificity: 0.9825\n",
      "\n",
      "Fold [7/10] Epoch [1/30], time cost: 67.9227,\n",
      " Train Cross Loss: 0.2348, Train Contras Loss: 1.3354 Train acc:  0.9037,\n",
      " Val Cross loss: 0.1462, Val Contras loss: 1.0422, Val accuracy: 0.9487, Sensitivity: 0.9513, Specificity: 0.9461\n",
      "\n",
      "Fold [7/10] Epoch [2/30], time cost: 66.7490,\n",
      " Train Cross Loss: 0.1457, Train Contras Loss: 0.8194 Train acc:  0.9454,\n",
      " Val Cross loss: 0.1037, Val Contras loss: 0.5990, Val accuracy: 0.9634, Sensitivity: 0.9894, Specificity: 0.9370\n",
      "\n",
      "Fold [7/10] Epoch [3/30], time cost: 64.2906,\n",
      " Train Cross Loss: 0.1211, Train Contras Loss: 0.6616 Train acc:  0.9564,\n",
      " Val Cross loss: 0.0879, Val Contras loss: 0.5185, Val accuracy: 0.9709, Sensitivity: 0.9818, Specificity: 0.9600\n",
      "\n",
      "Fold [7/10] Epoch [4/30], time cost: 142.9912,\n",
      " Train Cross Loss: 0.1050, Train Contras Loss: 0.5630 Train acc:  0.9634,\n",
      " Val Cross loss: 0.0855, Val Contras loss: 0.4920, Val accuracy: 0.9720, Sensitivity: 0.9777, Specificity: 0.9662\n",
      "\n",
      "Fold [7/10] Epoch [5/30], time cost: 67.1503,\n",
      " Train Cross Loss: 0.0948, Train Contras Loss: 0.4999 Train acc:  0.9678,\n",
      " Val Cross loss: 0.0695, Val Contras loss: 0.3917, Val accuracy: 0.9774, Sensitivity: 0.9890, Specificity: 0.9657\n",
      "\n",
      "Fold [7/10] Epoch [6/30], time cost: 66.8228,\n",
      " Train Cross Loss: 0.0862, Train Contras Loss: 0.4395 Train acc:  0.9708,\n",
      " Val Cross loss: 0.0881, Val Contras loss: 0.4629, Val accuracy: 0.9703, Sensitivity: 0.9615, Specificity: 0.9791\n",
      "\n",
      "Fold [7/10] Epoch [7/30], time cost: 67.4368,\n",
      " Train Cross Loss: 0.0820, Train Contras Loss: 0.4102 Train acc:  0.9722,\n",
      " Val Cross loss: 0.0632, Val Contras loss: 0.3390, Val accuracy: 0.9808, Sensitivity: 0.9878, Specificity: 0.9738\n",
      "\n",
      "Fold [7/10] Epoch [8/30], time cost: 66.7754,\n",
      " Train Cross Loss: 0.0735, Train Contras Loss: 0.3608 Train acc:  0.9761,\n",
      " Val Cross loss: 0.0604, Val Contras loss: 0.3188, Val accuracy: 0.9815, Sensitivity: 0.9968, Specificity: 0.9660\n",
      "\n",
      "Fold [7/10] Epoch [9/30], time cost: 70.0844,\n",
      " Train Cross Loss: 0.0683, Train Contras Loss: 0.3333 Train acc:  0.9782,\n",
      " Val Cross loss: 0.0922, Val Contras loss: 0.4362, Val accuracy: 0.9680, Sensitivity: 0.9986, Specificity: 0.9371\n",
      "\n",
      "Fold [7/10] Epoch [10/30], time cost: 71.1101,\n",
      " Train Cross Loss: 0.0666, Train Contras Loss: 0.3190 Train acc:  0.9787,\n",
      " Val Cross loss: 0.0563, Val Contras loss: 0.2864, Val accuracy: 0.9837, Sensitivity: 0.9856, Specificity: 0.9819\n",
      "\n",
      "Fold [7/10] Epoch [11/30], time cost: 67.3734,\n",
      " Train Cross Loss: 0.0619, Train Contras Loss: 0.2913 Train acc:  0.9804,\n",
      " Val Cross loss: 0.0554, Val Contras loss: 0.2811, Val accuracy: 0.9841, Sensitivity: 0.9877, Specificity: 0.9804\n",
      "\n",
      "Fold [7/10] Epoch [12/30], time cost: 67.3906,\n",
      " Train Cross Loss: 0.0593, Train Contras Loss: 0.2761 Train acc:  0.9813,\n",
      " Val Cross loss: 0.0526, Val Contras loss: 0.2747, Val accuracy: 0.9838, Sensitivity: 0.9956, Specificity: 0.9719\n",
      "\n",
      "Fold [7/10] Epoch [13/30], time cost: 68.4324,\n",
      " Train Cross Loss: 0.0558, Train Contras Loss: 0.2603 Train acc:  0.9826,\n",
      " Val Cross loss: 0.1120, Val Contras loss: 0.4868, Val accuracy: 0.9615, Sensitivity: 0.9342, Specificity: 0.9891\n",
      "\n",
      "Fold [7/10] Epoch [14/30], time cost: 68.0749,\n",
      " Train Cross Loss: 0.0528, Train Contras Loss: 0.2413 Train acc:  0.9833,\n",
      " Val Cross loss: 0.1601, Val Contras loss: 0.6094, Val accuracy: 0.9373, Sensitivity: 0.8828, Specificity: 0.9924\n",
      "\n",
      "Fold [7/10] Epoch [15/30], time cost: 67.2525,\n",
      " Train Cross Loss: 0.0533, Train Contras Loss: 0.2431 Train acc:  0.9834,\n",
      " Val Cross loss: 0.0474, Val Contras loss: 0.2497, Val accuracy: 0.9861, Sensitivity: 0.9935, Specificity: 0.9786\n",
      "\n",
      "Fold [7/10] Epoch [16/30], time cost: 69.7454,\n",
      " Train Cross Loss: 0.0514, Train Contras Loss: 0.2291 Train acc:  0.9840,\n",
      " Val Cross loss: 0.0651, Val Contras loss: 0.3049, Val accuracy: 0.9777, Sensitivity: 0.9671, Specificity: 0.9884\n",
      "\n",
      "Fold [7/10] Epoch [17/30], time cost: 69.1397,\n",
      " Train Cross Loss: 0.0475, Train Contras Loss: 0.2145 Train acc:  0.9852,\n",
      " Val Cross loss: 0.0446, Val Contras loss: 0.2445, Val accuracy: 0.9869, Sensitivity: 0.9923, Specificity: 0.9814\n",
      "\n",
      "Fold [7/10] Epoch [18/30], time cost: 71.5605,\n",
      " Train Cross Loss: 0.0476, Train Contras Loss: 0.2075 Train acc:  0.9848,\n",
      " Val Cross loss: 0.0514, Val Contras loss: 0.2445, Val accuracy: 0.9844, Sensitivity: 0.9825, Specificity: 0.9863\n",
      "\n",
      "Fold [7/10] Epoch [19/30], time cost: 71.0113,\n",
      " Train Cross Loss: 0.0433, Train Contras Loss: 0.1909 Train acc:  0.9867,\n",
      " Val Cross loss: 0.1133, Val Contras loss: 0.4372, Val accuracy: 0.9585, Sensitivity: 0.9248, Specificity: 0.9926\n",
      "\n",
      "Fold [7/10] Epoch [20/30], time cost: 70.0498,\n",
      " Train Cross Loss: 0.0440, Train Contras Loss: 0.1917 Train acc:  0.9866,\n",
      " Val Cross loss: 0.0497, Val Contras loss: 0.2315, Val accuracy: 0.9850, Sensitivity: 0.9994, Specificity: 0.9705\n",
      "\n",
      "Fold [7/10] Epoch [21/30], time cost: 71.5364,\n",
      " Train Cross Loss: 0.0421, Train Contras Loss: 0.1840 Train acc:  0.9869,\n",
      " Val Cross loss: 0.0417, Val Contras loss: 0.2136, Val accuracy: 0.9885, Sensitivity: 0.9972, Specificity: 0.9797\n",
      "\n",
      "Fold [7/10] Epoch [22/30], time cost: 68.9530,\n",
      " Train Cross Loss: 0.0398, Train Contras Loss: 0.1711 Train acc:  0.9878,\n",
      " Val Cross loss: 0.0585, Val Contras loss: 0.2659, Val accuracy: 0.9819, Sensitivity: 0.9992, Specificity: 0.9645\n",
      "\n",
      "Fold [7/10] Epoch [23/30], time cost: 71.1385,\n",
      " Train Cross Loss: 0.0391, Train Contras Loss: 0.1660 Train acc:  0.9883,\n",
      " Val Cross loss: 0.0480, Val Contras loss: 0.2300, Val accuracy: 0.9857, Sensitivity: 0.9846, Specificity: 0.9868\n",
      "\n",
      "Fold [7/10] Epoch [24/30], time cost: 71.3697,\n",
      " Train Cross Loss: 0.0381, Train Contras Loss: 0.1644 Train acc:  0.9888,\n",
      " Val Cross loss: 0.0379, Val Contras loss: 0.1826, Val accuracy: 0.9900, Sensitivity: 0.9977, Specificity: 0.9821\n",
      "\n",
      "Fold [7/10] Epoch [25/30], time cost: 70.0937,\n",
      " Train Cross Loss: 0.0371, Train Contras Loss: 0.1600 Train acc:  0.9887,\n",
      " Val Cross loss: 0.1117, Val Contras loss: 0.4049, Val accuracy: 0.9607, Sensitivity: 0.9304, Specificity: 0.9914\n",
      "\n",
      "Fold [7/10] Epoch [26/30], time cost: 70.5074,\n",
      " Train Cross Loss: 0.0362, Train Contras Loss: 0.1537 Train acc:  0.9888,\n",
      " Val Cross loss: 0.0439, Val Contras loss: 0.2324, Val accuracy: 0.9863, Sensitivity: 0.9877, Specificity: 0.9849\n",
      "\n",
      "Fold [7/10] Epoch [27/30], time cost: 70.5872,\n",
      " Train Cross Loss: 0.0365, Train Contras Loss: 0.1520 Train acc:  0.9889,\n",
      " Val Cross loss: 0.0425, Val Contras loss: 0.2289, Val accuracy: 0.9880, Sensitivity: 0.9936, Specificity: 0.9824\n",
      "\n",
      "Fold [7/10] Epoch [28/30], time cost: 53.3128,\n",
      " Train Cross Loss: 0.0340, Train Contras Loss: 0.1385 Train acc:  0.9900,\n",
      " Val Cross loss: 0.0451, Val Contras loss: 0.2304, Val accuracy: 0.9862, Sensitivity: 0.9983, Specificity: 0.9739\n",
      "\n",
      "Fold [7/10] Epoch [29/30], time cost: 64.4058,\n",
      " Train Cross Loss: 0.0335, Train Contras Loss: 0.1367 Train acc:  0.9902,\n",
      " Val Cross loss: 0.0498, Val Contras loss: 0.2728, Val accuracy: 0.9842, Sensitivity: 0.9916, Specificity: 0.9767\n",
      "\n",
      "Fold [7/10] Epoch [30/30], time cost: 67.4056,\n",
      " Train Cross Loss: 0.0340, Train Contras Loss: 0.1334 Train acc:  0.9901,\n",
      " Val Cross loss: 0.0490, Val Contras loss: 0.2273, Val accuracy: 0.9855, Sensitivity: 0.9985, Specificity: 0.9724\n",
      "['C4-P4', 'CZ-PZ', 'P4-O2', 'P8-O2', 'P7-O1', 'P3-O1']\n",
      "\n",
      "***********\n",
      "Best epoch: 23 Acc: 0.9899528015327819 Sensitivity for pre-ictal: 0.9976757158795091 Specificity: 0.9821478906323405\n",
      "***********\n",
      "\n",
      "Test Loss: 0.0423, Test accuracy: 0.9876, Sensitivity: 0.9968, Specificity: 0.9781\n",
      "\n",
      "Fold [8/10] Epoch [1/30], time cost: 69.3100,\n",
      " Train Cross Loss: 0.2284, Train Contras Loss: 1.2741 Train acc:  0.9074,\n",
      " Val Cross loss: 0.1504, Val Contras loss: 0.9159, Val accuracy: 0.9439, Sensitivity: 0.9222, Specificity: 0.9656\n",
      "\n",
      "Fold [8/10] Epoch [2/30], time cost: 72.5264,\n",
      " Train Cross Loss: 0.1375, Train Contras Loss: 0.7621 Train acc:  0.9486,\n",
      " Val Cross loss: 0.1015, Val Contras loss: 0.6283, Val accuracy: 0.9640, Sensitivity: 0.9745, Specificity: 0.9534\n",
      "\n",
      "Fold [8/10] Epoch [3/30], time cost: 71.6544,\n",
      " Train Cross Loss: 0.1118, Train Contras Loss: 0.5977 Train acc:  0.9607,\n",
      " Val Cross loss: 0.0918, Val Contras loss: 0.5498, Val accuracy: 0.9687, Sensitivity: 0.9849, Specificity: 0.9526\n",
      "\n",
      "Fold [8/10] Epoch [4/30], time cost: 68.7236,\n",
      " Train Cross Loss: 0.1012, Train Contras Loss: 0.5244 Train acc:  0.9659,\n",
      " Val Cross loss: 0.1046, Val Contras loss: 0.5357, Val accuracy: 0.9636, Sensitivity: 0.9977, Specificity: 0.9296\n",
      "\n",
      "Fold [8/10] Epoch [5/30], time cost: 70.2845,\n",
      " Train Cross Loss: 0.0908, Train Contras Loss: 0.4632 Train acc:  0.9689,\n",
      " Val Cross loss: 0.1282, Val Contras loss: 0.5745, Val accuracy: 0.9525, Sensitivity: 0.9226, Specificity: 0.9825\n",
      "\n",
      "Fold [8/10] Epoch [6/30], time cost: 68.4131,\n",
      " Train Cross Loss: 0.0822, Train Contras Loss: 0.4188 Train acc:  0.9729,\n",
      " Val Cross loss: 0.0699, Val Contras loss: 0.3906, Val accuracy: 0.9781, Sensitivity: 0.9923, Specificity: 0.9639\n",
      "\n",
      "Fold [8/10] Epoch [7/30], time cost: 69.3242,\n",
      " Train Cross Loss: 0.0816, Train Contras Loss: 0.3952 Train acc:  0.9731,\n",
      " Val Cross loss: 0.0907, Val Contras loss: 0.5115, Val accuracy: 0.9658, Sensitivity: 0.9584, Specificity: 0.9733\n",
      "\n",
      "Fold [8/10] Epoch [8/30], time cost: 72.1312,\n",
      " Train Cross Loss: 0.0719, Train Contras Loss: 0.3506 Train acc:  0.9770,\n",
      " Val Cross loss: 0.0982, Val Contras loss: 0.4423, Val accuracy: 0.9663, Sensitivity: 0.9995, Specificity: 0.9329\n",
      "\n",
      "Fold [8/10] Epoch [9/30], time cost: 70.8641,\n",
      " Train Cross Loss: 0.0691, Train Contras Loss: 0.3283 Train acc:  0.9773,\n",
      " Val Cross loss: 0.0696, Val Contras loss: 0.3883, Val accuracy: 0.9782, Sensitivity: 0.9932, Specificity: 0.9631\n",
      "\n",
      "Fold [8/10] Epoch [10/30], time cost: 72.3738,\n",
      " Train Cross Loss: 0.0646, Train Contras Loss: 0.3022 Train acc:  0.9796,\n",
      " Val Cross loss: 0.0622, Val Contras loss: 0.3269, Val accuracy: 0.9813, Sensitivity: 0.9868, Specificity: 0.9758\n",
      "\n",
      "Fold [8/10] Epoch [11/30], time cost: 71.9290,\n",
      " Train Cross Loss: 0.0601, Train Contras Loss: 0.2802 Train acc:  0.9812,\n",
      " Val Cross loss: 0.0606, Val Contras loss: 0.3107, Val accuracy: 0.9810, Sensitivity: 0.9825, Specificity: 0.9794\n",
      "\n",
      "Fold [8/10] Epoch [12/30], time cost: 74.2320,\n",
      " Train Cross Loss: 0.0570, Train Contras Loss: 0.2624 Train acc:  0.9823,\n",
      " Val Cross loss: 0.0702, Val Contras loss: 0.3401, Val accuracy: 0.9756, Sensitivity: 0.9988, Specificity: 0.9523\n",
      "\n",
      "Fold [8/10] Epoch [13/30], time cost: 75.2064,\n",
      " Train Cross Loss: 0.0518, Train Contras Loss: 0.2439 Train acc:  0.9842,\n",
      " Val Cross loss: 0.0569, Val Contras loss: 0.2930, Val accuracy: 0.9808, Sensitivity: 0.9985, Specificity: 0.9630\n",
      "\n",
      "Fold [8/10] Epoch [14/30], time cost: 73.7804,\n",
      " Train Cross Loss: 0.0511, Train Contras Loss: 0.2326 Train acc:  0.9841,\n",
      " Val Cross loss: 0.0879, Val Contras loss: 0.4098, Val accuracy: 0.9725, Sensitivity: 0.9985, Specificity: 0.9465\n",
      "\n",
      "Fold [8/10] Epoch [15/30], time cost: 74.2927,\n",
      " Train Cross Loss: 0.0484, Train Contras Loss: 0.2162 Train acc:  0.9854,\n",
      " Val Cross loss: 0.0757, Val Contras loss: 0.3303, Val accuracy: 0.9755, Sensitivity: 0.9997, Specificity: 0.9512\n",
      "\n",
      "Fold [8/10] Epoch [16/30], time cost: 72.1688,\n",
      " Train Cross Loss: 0.0454, Train Contras Loss: 0.2059 Train acc:  0.9861,\n",
      " Val Cross loss: 0.0711, Val Contras loss: 0.3625, Val accuracy: 0.9787, Sensitivity: 0.9962, Specificity: 0.9613\n",
      "\n",
      "Fold [8/10] Epoch [17/30], time cost: 72.9115,\n",
      " Train Cross Loss: 0.0462, Train Contras Loss: 0.2050 Train acc:  0.9862,\n",
      " Val Cross loss: 0.0489, Val Contras loss: 0.2476, Val accuracy: 0.9851, Sensitivity: 0.9989, Specificity: 0.9713\n",
      "\n",
      "Fold [8/10] Epoch [18/30], time cost: 72.8683,\n",
      " Train Cross Loss: 0.0438, Train Contras Loss: 0.1887 Train acc:  0.9873,\n",
      " Val Cross loss: 0.0480, Val Contras loss: 0.2422, Val accuracy: 0.9850, Sensitivity: 0.9981, Specificity: 0.9719\n",
      "\n",
      "Fold [8/10] Epoch [19/30], time cost: 71.8929,\n",
      " Train Cross Loss: 0.0416, Train Contras Loss: 0.1816 Train acc:  0.9876,\n",
      " Val Cross loss: 0.0650, Val Contras loss: 0.3049, Val accuracy: 0.9786, Sensitivity: 0.9997, Specificity: 0.9574\n",
      "\n",
      "Fold [8/10] Epoch [20/30], time cost: 72.0525,\n",
      " Train Cross Loss: 0.0423, Train Contras Loss: 0.1803 Train acc:  0.9872,\n",
      " Val Cross loss: 0.0484, Val Contras loss: 0.2552, Val accuracy: 0.9846, Sensitivity: 0.9976, Specificity: 0.9717\n",
      "\n",
      "Fold [8/10] Epoch [21/30], time cost: 74.3809,\n",
      " Train Cross Loss: 0.0384, Train Contras Loss: 0.1680 Train acc:  0.9885,\n",
      " Val Cross loss: 0.0611, Val Contras loss: 0.3048, Val accuracy: 0.9816, Sensitivity: 0.9993, Specificity: 0.9638\n",
      "\n",
      "Fold [8/10] Epoch [22/30], time cost: 75.6479,\n",
      " Train Cross Loss: 0.0375, Train Contras Loss: 0.1608 Train acc:  0.9887,\n",
      " Val Cross loss: 0.0488, Val Contras loss: 0.2707, Val accuracy: 0.9850, Sensitivity: 0.9952, Specificity: 0.9748\n",
      "\n",
      "Fold [8/10] Epoch [23/30], time cost: 75.2907,\n",
      " Train Cross Loss: 0.0357, Train Contras Loss: 0.1478 Train acc:  0.9898,\n",
      " Val Cross loss: 0.1135, Val Contras loss: 0.4657, Val accuracy: 0.9657, Sensitivity: 0.9998, Specificity: 0.9316\n",
      "\n",
      "Fold [8/10] Epoch [24/30], time cost: 73.1929,\n",
      " Train Cross Loss: 0.0357, Train Contras Loss: 0.1506 Train acc:  0.9894,\n",
      " Val Cross loss: 0.0460, Val Contras loss: 0.2311, Val accuracy: 0.9857, Sensitivity: 0.9869, Specificity: 0.9845\n",
      "\n",
      "Fold [8/10] Epoch [25/30], time cost: 72.9743,\n",
      " Train Cross Loss: 0.0353, Train Contras Loss: 0.1496 Train acc:  0.9892,\n",
      " Val Cross loss: 0.1032, Val Contras loss: 0.4029, Val accuracy: 0.9691, Sensitivity: 1.0000, Specificity: 0.9382\n",
      "\n",
      "Fold [8/10] Epoch [26/30], time cost: 72.7670,\n",
      " Train Cross Loss: 0.0344, Train Contras Loss: 0.1438 Train acc:  0.9898,\n",
      " Val Cross loss: 0.1138, Val Contras loss: 0.4699, Val accuracy: 0.9605, Sensitivity: 0.9996, Specificity: 0.9213\n",
      "\n",
      "Fold [8/10] Epoch [27/30], time cost: 70.5137,\n",
      " Train Cross Loss: 0.0343, Train Contras Loss: 0.1410 Train acc:  0.9901,\n",
      " Val Cross loss: 0.0632, Val Contras loss: 0.3010, Val accuracy: 0.9791, Sensitivity: 0.9997, Specificity: 0.9584\n",
      "\n",
      "Fold [8/10] Epoch [28/30], time cost: 71.5706,\n",
      " Train Cross Loss: 0.0326, Train Contras Loss: 0.1319 Train acc:  0.9901,\n",
      " Val Cross loss: 0.0497, Val Contras loss: 0.2584, Val accuracy: 0.9836, Sensitivity: 0.9843, Specificity: 0.9830\n",
      "\n",
      "Fold [8/10] Epoch [29/30], time cost: 71.4910,\n",
      " Train Cross Loss: 0.0302, Train Contras Loss: 0.1243 Train acc:  0.9914,\n",
      " Val Cross loss: 0.0538, Val Contras loss: 0.2785, Val accuracy: 0.9831, Sensitivity: 0.9983, Specificity: 0.9678\n",
      "\n",
      "Fold [8/10] Epoch [30/30], time cost: 71.7162,\n",
      " Train Cross Loss: 0.0311, Train Contras Loss: 0.1245 Train acc:  0.9909,\n",
      " Val Cross loss: 0.0623, Val Contras loss: 0.2969, Val accuracy: 0.9806, Sensitivity: 0.9989, Specificity: 0.9622\n",
      "['C4-P4', 'CZ-PZ', 'P4-O2', 'P8-O2', 'P7-O1', 'P3-O1']\n",
      "\n",
      "***********\n",
      "Best epoch: 23 Acc: 0.9857002663675872 Sensitivity for pre-ictal: 0.9869281045751634 Specificity: 0.9844700159042006\n",
      "***********\n",
      "\n",
      "Test Loss: 0.0484, Test accuracy: 0.9847, Sensitivity: 0.9862, Specificity: 0.9832\n",
      "\n",
      "Fold [9/10] Epoch [1/30], time cost: 72.1778,\n",
      " Train Cross Loss: 0.2332, Train Contras Loss: 1.3056 Train acc:  0.9057,\n",
      " Val Cross loss: 0.1399, Val Contras loss: 0.8648, Val accuracy: 0.9507, Sensitivity: 0.9633, Specificity: 0.9382\n",
      "\n",
      "Fold [9/10] Epoch [2/30], time cost: 73.1438,\n",
      " Train Cross Loss: 0.1412, Train Contras Loss: 0.7952 Train acc:  0.9469,\n",
      " Val Cross loss: 0.1332, Val Contras loss: 0.7510, Val accuracy: 0.9511, Sensitivity: 0.9924, Specificity: 0.9096\n",
      "\n",
      "Fold [9/10] Epoch [3/30], time cost: 72.1179,\n",
      " Train Cross Loss: 0.1185, Train Contras Loss: 0.6399 Train acc:  0.9570,\n",
      " Val Cross loss: 0.1577, Val Contras loss: 0.6628, Val accuracy: 0.9444, Sensitivity: 0.9102, Specificity: 0.9788\n",
      "\n",
      "Fold [9/10] Epoch [4/30], time cost: 72.7031,\n",
      " Train Cross Loss: 0.1041, Train Contras Loss: 0.5498 Train acc:  0.9637,\n",
      " Val Cross loss: 0.1002, Val Contras loss: 0.5837, Val accuracy: 0.9659, Sensitivity: 0.9701, Specificity: 0.9617\n",
      "\n",
      "Fold [9/10] Epoch [5/30], time cost: 72.1011,\n",
      " Train Cross Loss: 0.0915, Train Contras Loss: 0.4717 Train acc:  0.9694,\n",
      " Val Cross loss: 0.0982, Val Contras loss: 0.5742, Val accuracy: 0.9663, Sensitivity: 0.9910, Specificity: 0.9414\n",
      "\n",
      "Fold [9/10] Epoch [6/30], time cost: 72.3877,\n",
      " Train Cross Loss: 0.0830, Train Contras Loss: 0.4301 Train acc:  0.9722,\n",
      " Val Cross loss: 0.0813, Val Contras loss: 0.4478, Val accuracy: 0.9744, Sensitivity: 0.9963, Specificity: 0.9525\n",
      "\n",
      "Fold [9/10] Epoch [7/30], time cost: 71.8850,\n",
      " Train Cross Loss: 0.0779, Train Contras Loss: 0.3914 Train acc:  0.9746,\n",
      " Val Cross loss: 0.0771, Val Contras loss: 0.4553, Val accuracy: 0.9747, Sensitivity: 0.9777, Specificity: 0.9717\n",
      "\n",
      "Fold [9/10] Epoch [8/30], time cost: 71.8844,\n",
      " Train Cross Loss: 0.0737, Train Contras Loss: 0.3612 Train acc:  0.9758,\n",
      " Val Cross loss: 0.0701, Val Contras loss: 0.3935, Val accuracy: 0.9777, Sensitivity: 0.9883, Specificity: 0.9669\n",
      "\n",
      "Fold [9/10] Epoch [9/30], time cost: 72.0533,\n",
      " Train Cross Loss: 0.0683, Train Contras Loss: 0.3280 Train acc:  0.9779,\n",
      " Val Cross loss: 0.0916, Val Contras loss: 0.5462, Val accuracy: 0.9682, Sensitivity: 0.9874, Specificity: 0.9488\n",
      "\n",
      "Fold [9/10] Epoch [10/30], time cost: 72.5040,\n",
      " Train Cross Loss: 0.0631, Train Contras Loss: 0.3011 Train acc:  0.9802,\n",
      " Val Cross loss: 0.0734, Val Contras loss: 0.4061, Val accuracy: 0.9754, Sensitivity: 0.9892, Specificity: 0.9615\n",
      "\n",
      "Fold [9/10] Epoch [11/30], time cost: 71.1411,\n",
      " Train Cross Loss: 0.0602, Train Contras Loss: 0.2814 Train acc:  0.9810,\n",
      " Val Cross loss: 0.0559, Val Contras loss: 0.2924, Val accuracy: 0.9822, Sensitivity: 0.9979, Specificity: 0.9665\n",
      "\n",
      "Fold [9/10] Epoch [12/30], time cost: 71.5025,\n",
      " Train Cross Loss: 0.0576, Train Contras Loss: 0.2646 Train acc:  0.9822,\n",
      " Val Cross loss: 0.0675, Val Contras loss: 0.3529, Val accuracy: 0.9784, Sensitivity: 0.9977, Specificity: 0.9590\n",
      "\n",
      "Fold [9/10] Epoch [13/30], time cost: 72.2666,\n",
      " Train Cross Loss: 0.0556, Train Contras Loss: 0.2494 Train acc:  0.9831,\n",
      " Val Cross loss: 0.0651, Val Contras loss: 0.3229, Val accuracy: 0.9777, Sensitivity: 0.9984, Specificity: 0.9568\n",
      "\n",
      "Fold [9/10] Epoch [14/30], time cost: 71.7123,\n",
      " Train Cross Loss: 0.0508, Train Contras Loss: 0.2306 Train acc:  0.9845,\n",
      " Val Cross loss: 0.0662, Val Contras loss: 0.3287, Val accuracy: 0.9788, Sensitivity: 0.9734, Specificity: 0.9842\n",
      "\n",
      "Fold [9/10] Epoch [15/30], time cost: 72.7656,\n",
      " Train Cross Loss: 0.0496, Train Contras Loss: 0.2222 Train acc:  0.9854,\n",
      " Val Cross loss: 0.0585, Val Contras loss: 0.3060, Val accuracy: 0.9815, Sensitivity: 0.9980, Specificity: 0.9650\n",
      "\n",
      "Fold [9/10] Epoch [16/30], time cost: 71.8197,\n",
      " Train Cross Loss: 0.0495, Train Contras Loss: 0.2113 Train acc:  0.9848,\n",
      " Val Cross loss: 0.0569, Val Contras loss: 0.3037, Val accuracy: 0.9818, Sensitivity: 0.9846, Specificity: 0.9790\n",
      "\n",
      "Fold [9/10] Epoch [17/30], time cost: 71.9106,\n",
      " Train Cross Loss: 0.0441, Train Contras Loss: 0.1962 Train acc:  0.9865,\n",
      " Val Cross loss: 0.0503, Val Contras loss: 0.2626, Val accuracy: 0.9850, Sensitivity: 0.9922, Specificity: 0.9778\n",
      "\n",
      "Fold [9/10] Epoch [18/30], time cost: 71.2806,\n",
      " Train Cross Loss: 0.0420, Train Contras Loss: 0.1834 Train acc:  0.9876,\n",
      " Val Cross loss: 0.0582, Val Contras loss: 0.2820, Val accuracy: 0.9820, Sensitivity: 0.9996, Specificity: 0.9642\n",
      "\n",
      "Fold [9/10] Epoch [19/30], time cost: 72.0482,\n",
      " Train Cross Loss: 0.0421, Train Contras Loss: 0.1800 Train acc:  0.9869,\n",
      " Val Cross loss: 0.0595, Val Contras loss: 0.2690, Val accuracy: 0.9814, Sensitivity: 0.9994, Specificity: 0.9633\n",
      "\n",
      "Fold [9/10] Epoch [20/30], time cost: 72.0932,\n",
      " Train Cross Loss: 0.0396, Train Contras Loss: 0.1696 Train acc:  0.9877,\n",
      " Val Cross loss: 0.0616, Val Contras loss: 0.3125, Val accuracy: 0.9800, Sensitivity: 0.9752, Specificity: 0.9847\n",
      "\n",
      "Fold [9/10] Epoch [21/30], time cost: 72.4720,\n",
      " Train Cross Loss: 0.0389, Train Contras Loss: 0.1616 Train acc:  0.9885,\n",
      " Val Cross loss: 0.1052, Val Contras loss: 0.4072, Val accuracy: 0.9636, Sensitivity: 0.9385, Specificity: 0.9889\n",
      "\n",
      "Fold [9/10] Epoch [22/30], time cost: 70.7454,\n",
      " Train Cross Loss: 0.0395, Train Contras Loss: 0.1641 Train acc:  0.9878,\n",
      " Val Cross loss: 0.0537, Val Contras loss: 0.2721, Val accuracy: 0.9841, Sensitivity: 0.9961, Specificity: 0.9721\n",
      "\n",
      "Fold [9/10] Epoch [23/30], time cost: 71.3632,\n",
      " Train Cross Loss: 0.0368, Train Contras Loss: 0.1534 Train acc:  0.9891,\n",
      " Val Cross loss: 0.1064, Val Contras loss: 0.4724, Val accuracy: 0.9645, Sensitivity: 0.9459, Specificity: 0.9832\n",
      "\n",
      "Fold [9/10] Epoch [24/30], time cost: 71.9923,\n",
      " Train Cross Loss: 0.0375, Train Contras Loss: 0.1537 Train acc:  0.9886,\n",
      " Val Cross loss: 0.0464, Val Contras loss: 0.2368, Val accuracy: 0.9860, Sensitivity: 0.9981, Specificity: 0.9739\n",
      "\n",
      "Fold [9/10] Epoch [25/30], time cost: 72.8000,\n",
      " Train Cross Loss: 0.0350, Train Contras Loss: 0.1425 Train acc:  0.9896,\n",
      " Val Cross loss: 0.0476, Val Contras loss: 0.2566, Val accuracy: 0.9852, Sensitivity: 0.9960, Specificity: 0.9744\n",
      "\n",
      "Fold [9/10] Epoch [26/30], time cost: 73.4376,\n",
      " Train Cross Loss: 0.0332, Train Contras Loss: 0.1367 Train acc:  0.9902,\n",
      " Val Cross loss: 0.0484, Val Contras loss: 0.2477, Val accuracy: 0.9856, Sensitivity: 0.9986, Specificity: 0.9725\n",
      "\n",
      "Fold [9/10] Epoch [27/30], time cost: 73.4582,\n",
      " Train Cross Loss: 0.0342, Train Contras Loss: 0.1365 Train acc:  0.9895,\n",
      " Val Cross loss: 0.0584, Val Contras loss: 0.2667, Val accuracy: 0.9819, Sensitivity: 0.9999, Specificity: 0.9637\n",
      "\n",
      "Fold [9/10] Epoch [28/30], time cost: 72.4514,\n",
      " Train Cross Loss: 0.0316, Train Contras Loss: 0.1284 Train acc:  0.9905,\n",
      " Val Cross loss: 0.0582, Val Contras loss: 0.2812, Val accuracy: 0.9823, Sensitivity: 0.9979, Specificity: 0.9666\n",
      "\n",
      "Fold [9/10] Epoch [29/30], time cost: 72.3580,\n",
      " Train Cross Loss: 0.0310, Train Contras Loss: 0.1244 Train acc:  0.9908,\n",
      " Val Cross loss: 0.0556, Val Contras loss: 0.2505, Val accuracy: 0.9829, Sensitivity: 0.9994, Specificity: 0.9664\n",
      "\n",
      "Fold [9/10] Epoch [30/30], time cost: 74.4205,\n",
      " Train Cross Loss: 0.0309, Train Contras Loss: 0.1238 Train acc:  0.9904,\n",
      " Val Cross loss: 0.0581, Val Contras loss: 0.2862, Val accuracy: 0.9828, Sensitivity: 0.9985, Specificity: 0.9670\n",
      "['C4-P4', 'CZ-PZ', 'P4-O2', 'P8-O2', 'P7-O1', 'P3-O1']\n",
      "\n",
      "***********\n",
      "Best epoch: 23 Acc: 0.9860273844572176 Sensitivity for pre-ictal: 0.9981351981351981 Specificity: 0.9738617200674536\n",
      "***********\n",
      "\n",
      "Test Loss: 0.0448, Test accuracy: 0.9874, Sensitivity: 0.9973, Specificity: 0.9773\n",
      "\n",
      "Fold [10/10] Epoch [1/30], time cost: 72.8253,\n",
      " Train Cross Loss: 0.2295, Train Contras Loss: 1.2810 Train acc:  0.9057,\n",
      " Val Cross loss: 0.2317, Val Contras loss: 1.0773, Val accuracy: 0.9023, Sensitivity: 0.8250, Specificity: 0.9815\n",
      "\n",
      "Fold [10/10] Epoch [2/30], time cost: 72.3778,\n",
      " Train Cross Loss: 0.1395, Train Contras Loss: 0.7722 Train acc:  0.9491,\n",
      " Val Cross loss: 0.1030, Val Contras loss: 0.6149, Val accuracy: 0.9634, Sensitivity: 0.9655, Specificity: 0.9611\n",
      "\n",
      "Fold [10/10] Epoch [3/30], time cost: 73.1092,\n",
      " Train Cross Loss: 0.1131, Train Contras Loss: 0.6117 Train acc:  0.9595,\n",
      " Val Cross loss: 0.1095, Val Contras loss: 0.5499, Val accuracy: 0.9619, Sensitivity: 0.9970, Specificity: 0.9260\n",
      "\n",
      "Fold [10/10] Epoch [4/30], time cost: 72.5370,\n",
      " Train Cross Loss: 0.1025, Train Contras Loss: 0.5326 Train acc:  0.9647,\n",
      " Val Cross loss: 0.0788, Val Contras loss: 0.4352, Val accuracy: 0.9735, Sensitivity: 0.9925, Specificity: 0.9540\n",
      "\n",
      "Fold [10/10] Epoch [5/30], time cost: 72.5831,\n",
      " Train Cross Loss: 0.0914, Train Contras Loss: 0.4658 Train acc:  0.9685,\n",
      " Val Cross loss: 0.0965, Val Contras loss: 0.5523, Val accuracy: 0.9654, Sensitivity: 0.9541, Specificity: 0.9770\n",
      "\n",
      "Fold [10/10] Epoch [6/30], time cost: 72.0623,\n",
      " Train Cross Loss: 0.0876, Train Contras Loss: 0.4236 Train acc:  0.9707,\n",
      " Val Cross loss: 0.0675, Val Contras loss: 0.3662, Val accuracy: 0.9786, Sensitivity: 0.9918, Specificity: 0.9652\n",
      "\n",
      "Fold [10/10] Epoch [7/30], time cost: 72.2204,\n",
      " Train Cross Loss: 0.0757, Train Contras Loss: 0.3735 Train acc:  0.9744,\n",
      " Val Cross loss: 0.1200, Val Contras loss: 0.5431, Val accuracy: 0.9570, Sensitivity: 0.9983, Specificity: 0.9147\n",
      "\n",
      "Fold [10/10] Epoch [8/30], time cost: 71.7959,\n",
      " Train Cross Loss: 0.0721, Train Contras Loss: 0.3487 Train acc:  0.9763,\n",
      " Val Cross loss: 0.0853, Val Contras loss: 0.3999, Val accuracy: 0.9728, Sensitivity: 0.9988, Specificity: 0.9461\n",
      "\n",
      "Fold [10/10] Epoch [9/30], time cost: 73.1417,\n",
      " Train Cross Loss: 0.0682, Train Contras Loss: 0.3221 Train acc:  0.9781,\n",
      " Val Cross loss: 0.0578, Val Contras loss: 0.3113, Val accuracy: 0.9823, Sensitivity: 0.9874, Specificity: 0.9771\n",
      "\n",
      "Fold [10/10] Epoch [10/30], time cost: 72.5273,\n",
      " Train Cross Loss: 0.0619, Train Contras Loss: 0.2986 Train acc:  0.9804,\n",
      " Val Cross loss: 0.0575, Val Contras loss: 0.3081, Val accuracy: 0.9828, Sensitivity: 0.9941, Specificity: 0.9713\n",
      "\n",
      "Fold [10/10] Epoch [11/30], time cost: 72.3304,\n",
      " Train Cross Loss: 0.0584, Train Contras Loss: 0.2795 Train acc:  0.9815,\n",
      " Val Cross loss: 0.0928, Val Contras loss: 0.4370, Val accuracy: 0.9675, Sensitivity: 0.9994, Specificity: 0.9348\n",
      "\n",
      "Fold [10/10] Epoch [12/30], time cost: 72.4963,\n",
      " Train Cross Loss: 0.0563, Train Contras Loss: 0.2651 Train acc:  0.9825,\n",
      " Val Cross loss: 0.0514, Val Contras loss: 0.2704, Val accuracy: 0.9851, Sensitivity: 0.9895, Specificity: 0.9806\n",
      "\n",
      "Fold [10/10] Epoch [13/30], time cost: 72.7902,\n",
      " Train Cross Loss: 0.0523, Train Contras Loss: 0.2386 Train acc:  0.9840,\n",
      " Val Cross loss: 0.0565, Val Contras loss: 0.2952, Val accuracy: 0.9824, Sensitivity: 0.9980, Specificity: 0.9664\n",
      "\n",
      "Fold [10/10] Epoch [14/30], time cost: 72.7255,\n",
      " Train Cross Loss: 0.0487, Train Contras Loss: 0.2216 Train acc:  0.9851,\n",
      " Val Cross loss: 0.0560, Val Contras loss: 0.2758, Val accuracy: 0.9824, Sensitivity: 0.9805, Specificity: 0.9844\n",
      "\n",
      "Fold [10/10] Epoch [15/30], time cost: 74.0601,\n",
      " Train Cross Loss: 0.0512, Train Contras Loss: 0.2266 Train acc:  0.9842,\n",
      " Val Cross loss: 0.0487, Val Contras loss: 0.2586, Val accuracy: 0.9858, Sensitivity: 0.9914, Specificity: 0.9801\n",
      "\n",
      "Fold [10/10] Epoch [16/30], time cost: 72.7678,\n",
      " Train Cross Loss: 0.0471, Train Contras Loss: 0.2118 Train acc:  0.9856,\n",
      " Val Cross loss: 0.0531, Val Contras loss: 0.2642, Val accuracy: 0.9840, Sensitivity: 0.9989, Specificity: 0.9688\n",
      "\n",
      "Fold [10/10] Epoch [17/30], time cost: 73.3071,\n",
      " Train Cross Loss: 0.0457, Train Contras Loss: 0.1971 Train acc:  0.9856,\n",
      " Val Cross loss: 0.0542, Val Contras loss: 0.2722, Val accuracy: 0.9836, Sensitivity: 0.9968, Specificity: 0.9702\n",
      "\n",
      "Fold [10/10] Epoch [18/30], time cost: 73.2294,\n",
      " Train Cross Loss: 0.0447, Train Contras Loss: 0.1905 Train acc:  0.9861,\n",
      " Val Cross loss: 0.0470, Val Contras loss: 0.2481, Val accuracy: 0.9863, Sensitivity: 0.9970, Specificity: 0.9754\n",
      "\n",
      "Fold [10/10] Epoch [19/30], time cost: 74.2000,\n",
      " Train Cross Loss: 0.0417, Train Contras Loss: 0.1767 Train acc:  0.9875,\n",
      " Val Cross loss: 0.0477, Val Contras loss: 0.2699, Val accuracy: 0.9857, Sensitivity: 0.9867, Specificity: 0.9847\n",
      "\n",
      "Fold [10/10] Epoch [20/30], time cost: 73.0987,\n",
      " Train Cross Loss: 0.0410, Train Contras Loss: 0.1775 Train acc:  0.9874,\n",
      " Val Cross loss: 0.0507, Val Contras loss: 0.2717, Val accuracy: 0.9844, Sensitivity: 0.9968, Specificity: 0.9717\n",
      "\n",
      "Fold [10/10] Epoch [21/30], time cost: 70.6745,\n",
      " Train Cross Loss: 0.0392, Train Contras Loss: 0.1641 Train acc:  0.9884,\n",
      " Val Cross loss: 0.0417, Val Contras loss: 0.2096, Val accuracy: 0.9877, Sensitivity: 0.9987, Specificity: 0.9764\n",
      "\n",
      "Fold [10/10] Epoch [22/30], time cost: 72.3658,\n",
      " Train Cross Loss: 0.0378, Train Contras Loss: 0.1585 Train acc:  0.9886,\n",
      " Val Cross loss: 0.0649, Val Contras loss: 0.3051, Val accuracy: 0.9796, Sensitivity: 0.9733, Specificity: 0.9861\n",
      "\n",
      "Fold [10/10] Epoch [23/30], time cost: 72.0393,\n",
      " Train Cross Loss: 0.0384, Train Contras Loss: 0.1565 Train acc:  0.9880,\n",
      " Val Cross loss: 0.0460, Val Contras loss: 0.2468, Val accuracy: 0.9865, Sensitivity: 0.9971, Specificity: 0.9756\n",
      "\n",
      "Fold [10/10] Epoch [24/30], time cost: 72.1248,\n",
      " Train Cross Loss: 0.0342, Train Contras Loss: 0.1422 Train acc:  0.9894,\n",
      " Val Cross loss: 0.0456, Val Contras loss: 0.2314, Val accuracy: 0.9871, Sensitivity: 0.9969, Specificity: 0.9772\n",
      "\n",
      "Fold [10/10] Epoch [25/30], time cost: 71.7839,\n",
      " Train Cross Loss: 0.0356, Train Contras Loss: 0.1435 Train acc:  0.9888,\n",
      " Val Cross loss: 0.0467, Val Contras loss: 0.2537, Val accuracy: 0.9866, Sensitivity: 0.9933, Specificity: 0.9798\n",
      "\n",
      "Fold [10/10] Epoch [26/30], time cost: 72.2832,\n",
      " Train Cross Loss: 0.0347, Train Contras Loss: 0.1466 Train acc:  0.9897,\n",
      " Val Cross loss: 0.0431, Val Contras loss: 0.2254, Val accuracy: 0.9877, Sensitivity: 0.9985, Specificity: 0.9766\n",
      "\n",
      "Fold [10/10] Epoch [27/30], time cost: 71.4344,\n",
      " Train Cross Loss: 0.0334, Train Contras Loss: 0.1375 Train acc:  0.9901,\n",
      " Val Cross loss: 0.0488, Val Contras loss: 0.2427, Val accuracy: 0.9858, Sensitivity: 0.9850, Specificity: 0.9867\n",
      "\n",
      "Fold [10/10] Epoch [28/30], time cost: 72.0380,\n",
      " Train Cross Loss: 0.0321, Train Contras Loss: 0.1290 Train acc:  0.9901,\n",
      " Val Cross loss: 0.0438, Val Contras loss: 0.2449, Val accuracy: 0.9869, Sensitivity: 0.9893, Specificity: 0.9845\n",
      "\n",
      "Fold [10/10] Epoch [29/30], time cost: 68.6685,\n",
      " Train Cross Loss: 0.0323, Train Contras Loss: 0.1296 Train acc:  0.9903,\n",
      " Val Cross loss: 0.0541, Val Contras loss: 0.2582, Val accuracy: 0.9840, Sensitivity: 0.9996, Specificity: 0.9679\n",
      "\n",
      "Fold [10/10] Epoch [30/30], time cost: 70.9016,\n",
      " Train Cross Loss: 0.0321, Train Contras Loss: 0.1245 Train acc:  0.9903,\n",
      " Val Cross loss: 0.0482, Val Contras loss: 0.2254, Val accuracy: 0.9862, Sensitivity: 0.9994, Specificity: 0.9728\n",
      "['C4-P4', 'CZ-PZ', 'P4-O2', 'P8-O2', 'P7-O1', 'P3-O1']\n",
      "\n",
      "***********\n",
      "Best epoch: 25 Acc: 0.9877097060610309 Sensitivity for pre-ictal: 0.9985218033998522 Specificity: 0.9766430260047282\n",
      "***********\n",
      "\n",
      "Test Loss: 0.0532, Test accuracy: 0.9844, Sensitivity: 0.9988, Specificity: 0.9698\n",
      "\n",
      "\n",
      "Avg test acc: 0.9865, avg test sensitivity: 0.9950, avg test specificity: 0.9779 \n",
      "\n",
      "['chb09']\n",
      "step_for_overlap: 31\n",
      "60636668 1843204\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 145\u001b[0m\n\u001b[0;32m    143\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    144\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 145\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# functional.reset_net( model )\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# print(outputs.shape, targets.shape)\u001b[39;00m\n\u001b[0;32m    150\u001b[0m predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#(outputs > 0.5).float()\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\EEG_seizure\\Lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\EEG_seizure\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\EEG_seizure\\Lib\\site-packages\\torch\\optim\\adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    160\u001b[0m         group,\n\u001b[0;32m    161\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    166\u001b[0m         state_steps)\n\u001b[1;32m--> 168\u001b[0m     adam(\n\u001b[0;32m    169\u001b[0m         params_with_grad,\n\u001b[0;32m    170\u001b[0m         grads,\n\u001b[0;32m    171\u001b[0m         exp_avgs,\n\u001b[0;32m    172\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    173\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    174\u001b[0m         state_steps,\n\u001b[0;32m    175\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    176\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    177\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    178\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    179\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    180\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    181\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    182\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    183\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    184\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    185\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    186\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    187\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    188\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    189\u001b[0m     )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\EEG_seizure\\Lib\\site-packages\\torch\\optim\\adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 318\u001b[0m func(params,\n\u001b[0;32m    319\u001b[0m      grads,\n\u001b[0;32m    320\u001b[0m      exp_avgs,\n\u001b[0;32m    321\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    322\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    323\u001b[0m      state_steps,\n\u001b[0;32m    324\u001b[0m      amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    325\u001b[0m      has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    326\u001b[0m      beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    327\u001b[0m      beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    328\u001b[0m      lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m    329\u001b[0m      weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    330\u001b[0m      eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    331\u001b[0m      maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[0;32m    332\u001b[0m      capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m    333\u001b[0m      differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[0;32m    334\u001b[0m      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[0;32m    335\u001b[0m      found_inf\u001b[38;5;241m=\u001b[39mfound_inf)\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\EEG_seizure\\Lib\\site-packages\\torch\\optim\\adam.py:510\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# Update steps\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# If steps are on CPU, foreach will fall back to the slow path, which is a for-loop calling t.add(1) over\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# and over. 1 will then be wrapped into a Tensor over and over again, which is slower than if we just\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# wrapped it once now. The alpha is required to assure we go to the right overload.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_state_steps[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mis_cpu:\n\u001b[1;32m--> 510\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_add_(device_state_steps, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1.0\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m), alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    512\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_add_(device_state_steps, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "patient_index_list = [5, 6, 8, 12, 13, 15, 16, 19, 1, 2, 3]\n",
    "# patient_index_list = [1, 2, 3]\n",
    "for patient_index in range(7, 24+1):\n",
    "    if patient_index in patient_index_list:\n",
    "        continue\n",
    "    # 设置数据文件夹路径\n",
    "    data_folder = 'E:\\\\EEG\\\\chb-mit-scalp-eeg-database-1.0.0'\n",
    "    # patients_folder = []\n",
    "    # for i in range(1, 25):\n",
    "    #     if i < 10:\n",
    "    #         patients_folder.append(\"chb0\"+str(i))\n",
    "    #     else:\n",
    "    #         patients_folder.append(\"chb\"+str(i))\n",
    "    # os.path.join(data_folder, patients_folder[0])\n",
    "    \n",
    "    # NUM_OF_PATIENTS_USED = 1000 # Use all data\n",
    "    PATIENT_TO_USE = ['chb'+str(patient_index).zfill(2)] #06' #('chb0' + str(patient_index)) if patient_index < 10 else 'chb'+str(patient_index) #chb04'\n",
    "    print(PATIENT_TO_USE)\n",
    "\n",
    "    with open(PATIENT_TO_USE[0]+'_sel_ch_30iter_with_SMOTE.json', 'r') as json_file:\n",
    "        loaded_data = json.load(json_file)\n",
    "    \n",
    "    COMMON_CH, _ = top_n_elements( loaded_data, 6 ) # 8 channels are acceptable\n",
    "\n",
    "    log_file_name = 'chb'+str(patient_index).zfill(2)+'_'+str(len(COMMON_CH))+'chs_log_with_mamba_10fold.txt'\n",
    "    with open(log_file_name, \"w\") as f:\n",
    "        f.write(\"AddNet-SCL With Mamba 1D - 10-fold\\n\" + str(len(COMMON_CH)) + \" channels\\n\" )\n",
    "    \n",
    "    SAMPLE_RATE = 256\n",
    "    DOWN_SAMP_RATE = 1\n",
    "    NEW_SAMP_RATE = int(SAMPLE_RATE / DOWN_SAMP_RATE)\n",
    "    \n",
    "    # split the raw data to 5 sec segments\n",
    "    SEG_TIME = 4\n",
    "    SEG_LEN = NEW_SAMP_RATE * SEG_TIME\n",
    "\n",
    "    \n",
    "    # STEP_FOR_OVERLAP = int(NEW_SAMP_RATE * (SEG_TIME - OVERLAP_TIME))\n",
    "    # STEP_NO_OVERLAP  = SEG_LEN\n",
    "    \n",
    "    # SPH = 15 * 60 * NEW_SAMP_RATE# Seizure Prediction Horizon (SPH)\n",
    "    # PIL = (15+SPH) * 60 * NEW_SAMP_RATE# Pre-ictal interval (PIL)\n",
    "    # POST_ICTAL_LEN = 15 * 60 * NEW_SAMP_RATE\n",
    "    \n",
    "    # # Different patients have different channels, so pick the commont channels\n",
    "    # COMMON_CH_TOTAL = ['P4-O2', 'T7-P7', 'C4-P4', 'FZ-CZ', 'F3-C3', 'P7-O1', 'CZ-PZ', 'P8-O2', 'F4-C4', 'P3-O1', 'FP2-F8', 'F8-T8', 'FP1-F3', 'F7-T7', 'C3-P3', 'FP1-F7', 'FP2-F4']\n",
    "    \n",
    "    \n",
    "    \n",
    "    # These files have no common channels with other files\n",
    "    FILE_EXCLUDED = ['chb12_27.edf', 'chb12_28.edf', 'chb12_29.edf'] \n",
    "    \n",
    "    logger = logging.getLogger('mne')\n",
    "    # logger.setLevel(logging.WARNING)\n",
    "    logger.setLevel(logging.ERROR) # 每读一个edf文件都会有一个通道名重复的警告\n",
    "    \n",
    "    \n",
    "    SEIZURE_FOR_TEST = 4\n",
    "    # 导入数据\n",
    "    raws = []\n",
    "    file_names = []\n",
    "    labels = []\n",
    "    sec_seizure = {}\n",
    "    \n",
    "    seizure_cnt = 0\n",
    "        \n",
    "    segments_inter, segments_pre = read_edf_data_separately( data_folder, PATIENT_TO_USE, COMMON_CH, SEG_TIME )\n",
    "    \n",
    "    segments = ListMerger( segments_inter, segments_pre )\n",
    "    seg_labels = [0] * len(segments_inter) + [1] * len(segments_pre)\n",
    "    seg_labels = torch.nn.functional.one_hot(torch.tensor(seg_labels), num_classes=2)\n",
    "    \n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    test_acc = []\n",
    "    test_sens = []\n",
    "    test_spec = []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(segments, seg_labels.argmax(axis=1))):\n",
    "        # 获取训练和测试数据，都是np.array\n",
    "        X_train_indices = train_index\n",
    "        X_test_indices = test_index\n",
    "    \n",
    "        # 从训练集中划分出验证集\n",
    "        val_size = int(len(X_train_indices) * 0.2)  # 20% 用作验证集\n",
    "        val_indices = np.random.choice(X_train_indices, size=val_size, replace=False)\n",
    "        train_indices = np.setdiff1d(X_train_indices, val_indices)\n",
    "    \n",
    "        # 创建数据集\n",
    "        train_dataset = MergedDataset(segments, seg_labels, train_indices)\n",
    "        val_dataset = MergedDataset(segments, seg_labels, val_indices)\n",
    "        test_dataset = MergedDataset(segments, seg_labels, X_test_indices)\n",
    "    \n",
    "        # 创建数据加载器\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)#, pin_memory=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)#, pin_memory=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)#, pin_memory=True)\n",
    "        # break\n",
    "    \n",
    "        best_test_accuracy = 0\n",
    "        best_epoch = -1\n",
    "        sens_p = 0\n",
    "        spec_p = 0\n",
    "        \n",
    "        \n",
    "        model = OneDCNN(len(COMMON_CH)).to(device)\n",
    "        if patient_index == 1:\n",
    "            summary(model, input_size=(len(COMMON_CH), 1024))\n",
    "        # criterion = nn.MSELoss().to(device)\n",
    "        # criterion = nn.BCELoss().to(device)\n",
    "        criterion = nn.CrossEntropyLoss().to(device)\n",
    "        super_contras = SupervisedContrastiveLoss(0.08).to(device)\n",
    "        # criterion = WeightedMSELoss(4).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "        \n",
    "        num_epochs = 30\n",
    "        # VOTE_NUM = 5\n",
    "        y_test = np.array(seg_labels[X_test_indices])\n",
    "        y_test = np.argmax( y_test, axis=1)\n",
    "        y_val = np.array(seg_labels[val_indices])\n",
    "        y_val = np.argmax( y_val, axis=1)\n",
    "        # y_test_flat = y_test[VOTE_NUM - 1:]\n",
    "        for epoch in range(num_epochs):\n",
    "            start_time = time.time()\n",
    "            # 训练阶段\n",
    "            model.train()\n",
    "            \n",
    "            train_loss = 0.0\n",
    "            train_loss_cross = 0.0\n",
    "            train_loss_cont  = 0.0\n",
    "            \n",
    "            correct = 0\n",
    "            for interation, (inputs, targets) in enumerate(train_loader):\n",
    "                # print(interation)\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device).float()\n",
    "                outputs, feats = model(inputs)\n",
    "                loss_cross = criterion(outputs, targets)\n",
    "                tars = targets.argmax(dim=1)\n",
    "                # print(tars.shape)\n",
    "                loss_cont = super_contras( feats, tars )\n",
    "                loss = 0.5 * loss_cross + 0.5 * loss_cont\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # functional.reset_net( model )\n",
    "        \n",
    "                # print(outputs.shape, targets.shape)\n",
    "                predicted = torch.argmax(outputs, dim=1) #(outputs > 0.5).float()\n",
    "                targets = torch.argmax(targets, dim=1) #(targets>0.5).to(device)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "        \n",
    "                train_loss += loss.item()\n",
    "                train_loss_cross += loss_cross.item()\n",
    "                train_loss_cont  += loss_cont.item()\n",
    "                   \n",
    "            train_loss /= len(train_loader)\n",
    "            train_loss_cross /= len(train_loader)\n",
    "            train_loss_cont /= len(train_loader)\n",
    "            train_acc = correct / len(train_dataset)\n",
    "        \n",
    "        \n",
    "            # 验证阶段\n",
    "            model.eval()\n",
    "            \n",
    "            val_loss = 0.0\n",
    "            val_loss_cross = 0.0\n",
    "            val_loss_cont  = 0.0\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            TP = 0\n",
    "            FN = 0\n",
    "            TN = 0\n",
    "            FP = 0\n",
    "            predictions = []\n",
    "            # targets = []\n",
    "            with torch.inference_mode():\n",
    "                for inputs, targets in val_loader:\n",
    "                    inputs = inputs.to(device)\n",
    "                    targets = targets.to(device).float()\n",
    "                    outputs, feats = model(inputs)\n",
    "                    predicted = torch.argmax(outputs, dim=1) #(outputs > 0.5).float()\n",
    "                    loss_cross = criterion(outputs, targets)\n",
    "                    tars = targets.argmax(dim=1)\n",
    "                    loss_cont = super_contras( feats, tars )\n",
    "                    loss = loss_cross + loss_cont\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    val_loss_cross += loss_cross.item()\n",
    "                    val_loss_cont += loss_cont.item()\n",
    "                    \n",
    "                    predictions.extend( predicted.cpu() )\n",
    "                    \n",
    "                    # functional.reset_net( model )\n",
    "        \n",
    "                predictions = np.array( predictions )\n",
    "                # final_predictions_flat = np.array( [ mode(predictions[ i-(VOTE_NUM-1) : i+1 ]).mode for i in range(VOTE_NUM-1, len(predictions)) ] )\n",
    "                \n",
    "                # 计算混淆矩阵的四个基本元素\n",
    "                TP = np.sum((predictions == 1) & (y_val == 1))  # True Positives\n",
    "                TN = np.sum((predictions == 0) & (y_val == 0))  # True Negatives\n",
    "                FP = np.sum((predictions == 1) & (y_val == 0))  # False Positives\n",
    "                FN = np.sum((predictions == 0) & (y_val == 1))  # False Negatives\n",
    "                \n",
    "                    \n",
    "                    \n",
    "            val_loss /= len(val_loader)\n",
    "            val_loss_cross /= len(val_loader)\n",
    "            val_loss_cont  /= len(val_loader)\n",
    "            \n",
    "            test_accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "            sens_p_epoch = TP / (TP + FN) if (TP+FN != 0 ) else 0\n",
    "            spec_p_epoch = TN / (TN + FP) if (TN+FP != 0 ) else 0\n",
    "        \n",
    "            \n",
    "            if test_accuracy > best_test_accuracy: # sens_p_epoch > sens_p:  \n",
    "                best_test_accuracy = test_accuracy\n",
    "                best_epoch = epoch\n",
    "                sens_p = TP / (TP + FN) if (TP+FN != 0 ) else 0\n",
    "                spec_p = TN / (TN + FP) if (TN+FP != 0 ) else 0\n",
    "                torch.save(model, PATIENT_TO_USE[0]+str(best_epoch)+'.pt')\n",
    "            end_time = time.time()\n",
    "            time_cost = end_time - start_time\n",
    "            # print(f'\\nEpoch [{epoch+1}/{num_epochs}], time cost: {time_cost:.4f},\\n Train Cross Loss: {train_loss_cross:.4f}, Train Contras Loss: {train_loss_cont:.4f} Train acc: {train_acc: .4f},\\n Val Cross loss: {val_loss_cross:.4f}, Val Contras loss: {val_loss_cont:.4f}, Test accuracy: {test_accuracy:.4f}, Sensitivity: {sens_p_epoch:.4f}, Specificity: {spec_p_epoch:.4f}, Test acc vote: {test_acc_vote:.4f}, Sens vote: {sens_p_epoch_vote:.4f}, Spec vote: {spec_p_epoch_vote:.4f}')\n",
    "            training_info = f'\\nFold [{i+1}/10] Epoch [{epoch+1}/{num_epochs}], time cost: {time_cost:.4f},\\n Train Cross Loss: {train_loss_cross:.4f}, Train Contras Loss: {train_loss_cont:.4f} Train acc: {train_acc: .4f},\\n Val Cross loss: {val_loss_cross:.4f}, Val Contras loss: {val_loss_cont:.4f}, Val accuracy: {test_accuracy:.4f}, Sensitivity: {sens_p_epoch:.4f}, Specificity: {spec_p_epoch:.4f}'\n",
    "            print(training_info)\n",
    "            with open(log_file_name, 'a') as f:\n",
    "                f.write( training_info+'\\n' )\n",
    "        \n",
    "\n",
    "        train_summary = ', '.join(COMMON_CH)\n",
    "        train_summary = train_summary + f'\\n***********\")\\nBest epoch: {best_epoch}, Acc: {best_test_accuracy}, Sensitivity for pre-ictal: {sens_p}, Specificity: {spec_p}\\n***********\\n'\n",
    "        with open(log_file_name, 'a') as f:\n",
    "            f.write( train_summary )\n",
    "        print(COMMON_CH)\n",
    "        # print(\"***********\\nSensitivity for pre-ictal:\", sens_p, \", sensitivity for inter:\", sens_inter)\n",
    "        print(\"\\n***********\")\n",
    "        print(\"Best epoch:\", best_epoch, \"Acc:\", best_test_accuracy, \"Sensitivity for pre-ictal:\", sens_p, \"Specificity:\", spec_p)\n",
    "        print(\"***********\\n\")\n",
    "    \n",
    "    \n",
    "        model_for_test = torch.load( PATIENT_TO_USE[0]+str(best_epoch)+'.pt' )\n",
    "        model_for_test.eval()\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        # total = 0\n",
    "        TP = 0\n",
    "        FN = 0\n",
    "        TN = 0\n",
    "        FP = 0\n",
    "        predictions = []\n",
    "        outputs_list = []\n",
    "        with torch.inference_mode():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device).float()\n",
    "        \n",
    "                # print( inputs.shape, targets.shape )\n",
    "                \n",
    "                outputs, feats = model_for_test(inputs)\n",
    "        \n",
    "                # print( outputs.shape, targets )\n",
    "                # break\n",
    "                \n",
    "                predicted = torch.argmax(outputs, dim=1) #(outputs >= 0.5).float()\n",
    "                loss = criterion(outputs, targets)\n",
    "                targets = torch.argmax(targets, dim=1)\n",
    "                test_loss += loss.item()\n",
    "                # total += targets.size(0)\n",
    "                positive_labels = ( targets == 1 )\n",
    "                correct += (predicted == targets).sum().item()\n",
    "                TP += ( positive_labels * ( predicted == targets ) ).sum().item()\n",
    "                FN += ( positive_labels * ( predicted != targets ) ).sum().item()\n",
    "                # functional.reset_net( model )\n",
    "        \n",
    "                predictions.extend(predicted.cpu())\n",
    "                outputs_list.extend(outputs.cpu())\n",
    "                \n",
    "                # print(predicted.shape, targets.shape)\n",
    "                \n",
    "                # break\n",
    "        predictions = np.array( predictions)\n",
    "        TP = np.sum((predictions == 1) & (y_test == 1))  # True Positives\n",
    "        TN = np.sum((predictions == 0) & (y_test == 0))  # True Negatives\n",
    "        FP = np.sum((predictions == 1) & (y_test == 0))  # False Positives\n",
    "        FN = np.sum((predictions == 0) & (y_test == 1))  # False Negatives\n",
    "            \n",
    "        \n",
    "        test_loss /= len(test_loader)\n",
    "        test_accuracy = correct / len(test_dataset)\n",
    "        test_sensitivity = TP / (TP + FN) if (TP+FN != 0 ) else 0\n",
    "        test_specificity = TN / (TN + FP) if (TN+FP != 0 ) else 0\n",
    "\n",
    "        test_info = f'Test Loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}, Sensitivity: {test_sensitivity:.4f}, Specificity: {test_specificity:.4f}'\n",
    "        with open(log_file_name, 'a') as f:\n",
    "            f.write( test_info )\n",
    "        print(test_info)\n",
    "    \n",
    "        test_acc.append( test_accuracy )\n",
    "        test_sens.append( test_sensitivity )\n",
    "        test_spec.append( test_specificity )\n",
    "    \n",
    "        # break # only use 80-20 split for channel experiments\n",
    "    \n",
    "    avg_test_info = f'\\n\\nAvg test acc: {sum(test_acc)/len(test_acc):.4f}, avg test sensitivity: {sum(test_sens)/len(test_sens):.4f}, avg test specificity: {sum(test_spec)/len(test_spec):.4f} \\n'\n",
    "    with open(log_file_name, 'a') as f:\n",
    "        f.write( avg_test_info )\n",
    "    print( avg_test_info )\n",
    "    # print( \"Avg test acc:\", sum(test_acc)/len(test_acc), \"avg test sensitivity:\", sum(test_sens)/len(test_sens), \"avg test specificity\", sum(test_spec)/len(test_spec) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b684c1-ff88-4003-9f60-9b37ce56060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inputs, targets in train_loader:\n",
    "#     print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a78f1-b228-4cb6-a83b-ed6d4b613e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary( model, (8, 1024) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1191cfd2-fef1-4140-9c17-02585ffb4c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "type( segments_pre )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2dfbcf-3b09-4e03-84d8-c9beeff1c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(segments_pre) / len(segments_inter), test_sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c91c0d-4630-4a50-8ff2-5de7f7051497",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( sum(test_acc)/len(test_acc), sum(test_sens)/len(test_sens), sum(test_spec)/len(test_spec) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea744bf-259f-4f05-afca-e25b1c2a736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_test = torch.load( PATIENT_TO_USE[0]+str(best_epoch)+'.pt' )\n",
    "model_for_test.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "# total = 0\n",
    "TP = 0\n",
    "FN = 0\n",
    "predictions = []\n",
    "outputs_list = []\n",
    "with torch.inference_mode():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device).float()\n",
    "\n",
    "        # print( inputs.shape, targets.shape )\n",
    "        \n",
    "        outputs, feats = model_for_test(inputs)\n",
    "\n",
    "        # print( outputs.shape, targets )\n",
    "        # break\n",
    "        \n",
    "        predicted = torch.argmax(outputs, dim=1) #(outputs >= 0.5).float()\n",
    "        loss = criterion(outputs, targets)\n",
    "        targets = torch.argmax(targets, dim=1)\n",
    "        test_loss += loss.item()\n",
    "        # total += targets.size(0)\n",
    "        positive_labels = ( targets == 1 )\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        # print( (predicted == targets).sum().item() )\n",
    "        TP += ( positive_labels * ( predicted == targets ) ).sum().item()\n",
    "        FN += ( positive_labels * ( predicted != targets ) ).sum().item()\n",
    "        # functional.reset_net( model )\n",
    "\n",
    "        predictions.extend(predicted.cpu())\n",
    "        outputs_list.extend(outputs.cpu())\n",
    "        \n",
    "        # print(predicted.shape, targets.shape)\n",
    "        \n",
    "        # break\n",
    "predictions = np.array( predictions)\n",
    "TP = np.sum((predictions == 1) & (y_test == 1))  # True Positives\n",
    "TN = np.sum((predictions == 0) & (y_test == 0))  # True Negatives\n",
    "FP = np.sum((predictions == 1) & (y_test == 0))  # False Positives\n",
    "FN = np.sum((predictions == 0) & (y_test == 1))  # False Negatives\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "test_sensitivity = TP / (TP + FN) if (TP+FN != 0 ) else 0\n",
    "test_specificity = TN / (TN + FP) if (TN+FP != 0 ) else 0\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}, Sensitivity: {test_sensitivity:.4f}, Specificity: {test_specificity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b70e88-6c94-40dd-8931-04914b5d077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.shape, targets.shape, correct, len(test_loader), len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb764047-dcbf-4ac9-9bad-3001ea8a23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "large_list1 = list(range(1000000))\n",
    "\n",
    "large_list2 = list(range(1000000, 2000000))\n",
    "\n",
    "merged_list = ListMerger(large_list1, large_list2)\n",
    "\n",
    "merged_list[1000000-2 : 1000000+2], large_list1[-2:], large_list2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb368850-5fe6-40e9-9f3a-5bcaaa0829a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "X1 = np.random.rand(10, 3)  # 100 个样本，10 个特征\n",
    "X2 = np.random.rand(10, 3)  # 另一个特征集\n",
    "y = np.random.randint(0, 2, size=(100,))  # 100 个标签（0 或 1）\n",
    "\n",
    "# 创建 ListMerger 实例\n",
    "X = ListMerger(X1, X2)\n",
    "\n",
    "# 创建 KFold 实例\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# KFold 交叉验证\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print( type(train_index) )\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e627e09e-f248-43d8-9cec-8a5b169ecb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_labels_for_train.shape, seg_labels_for_test.shape, pre_len_for_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f37d2-3a20-4e0e-915e-d41c975464ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pre_start, target_pre_end, seg_labels[target_pre_start-1:target_pre_end+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f52716b-18fc-473a-bb61-5a2b3181a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_len_for_test  * 15 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db91f1-f7e4-4200-9025-9ddf63c16be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seg_labels), index  #_for_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af10c6b7-0dd1-4a44-ae10-814911870057",
   "metadata": {},
   "outputs": [],
   "source": [
    "896/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4968c2ea-1199-436b-899c-056d8d84c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "functional.reset_net( model )\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "TP = 0\n",
    "FN = 0\n",
    "predictions = []\n",
    "outputs_list = []\n",
    "with torch.inference_mode():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # print( inputs.shape, targets.shape )\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # print( outputs.shape, targets )\n",
    "        # break\n",
    "        \n",
    "        predicted = (outputs >= 0.5).float()\n",
    "        loss = criterion(outputs, targets)\n",
    "        val_loss += loss.item()\n",
    "        total += targets.size(0)\n",
    "        positive_labels = ( targets == 1 )\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        TP += ( positive_labels * ( predicted == targets ) ).sum().item()\n",
    "        FN += ( positive_labels * ( predicted != targets ) ).sum().item()\n",
    "        functional.reset_net( model )\n",
    "\n",
    "        predictions.extend(predicted.cpu())\n",
    "        outputs_list.extend(outputs.cpu())\n",
    "        \n",
    "        # print(predicted.shape, targets.shape)\n",
    "        \n",
    "        # break\n",
    "predictions = np.array( predictions)\n",
    "TP = np.sum((predictions == 1) & (y_test == 1))  # True Positives\n",
    "TN = np.sum((predictions == 0) & (y_test == 0))  # True Negatives\n",
    "FP = np.sum((predictions == 1) & (y_test == 0))  # False Positives\n",
    "FN = np.sum((predictions == 0) & (y_test == 1))  # False Negatives\n",
    "# outputs_list = np.array( outputs_list)\n",
    "val_loss /= len(val_loader)\n",
    "test_accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "sens_p_epoch = TP / (TP + FN) if (TP+FN != 0 ) else sens_p\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "    sens_p = TP / (TP + FN) if (TP+FN != 0 ) else sens_p\n",
    "print(f'Epoch [{epoch+1}/{num_epochs}], Test Loss: {val_loss:.4f}, Test accuracy: {test_accuracy:.4f}, Sensitivity: {sens_p_epoch:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec837c-f990-4991-8aea-e23ee5d0c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions.shape, seg_labels_for_test.shape, outputs_list\n",
    "print( step_on_both_sides, pre_len_for_test )\n",
    "corrects_list = predictions == seg_labels_for_test\n",
    "TPaaa = (predictions == 1) & (y_test == 1) \n",
    "TPaaa[120:120+120], outputs_list[60:60+120]\n",
    "segments.min()\n",
    "(outputs_list > 0.5).sum() / len(outputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ea2ff-2807-4d62-9de9-d6b9271cc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((1, 10))\n",
    "b = np.ones((1, 10))\n",
    "b[0][4] = 0\n",
    "( a == 1 ) & ( b == 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb96a7ae-564f-4bca-b754-acdbd6542ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    print(inputs)\n",
    "    print(model(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bd4e12-4e2e-47b5-a158-f956ac7e1ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "functional.reset_net( model )\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "TP = 0\n",
    "FN = 0\n",
    "\n",
    "out_list = []\n",
    "with torch.inference_mode():\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        out_list.extend(outputs.cpu())\n",
    "\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        loss = criterion(outputs, targets)\n",
    "        val_loss += loss.item()\n",
    "        total += targets.size(0)\n",
    "        positive_labels = ( predicted == 1 )\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        TP += ( positive_labels * ( predicted == targets ) ).sum().item()\n",
    "        FN += ( positive_labels * ( predicted != targets ) ).sum().item()\n",
    "        functional.reset_net( model )\n",
    "\n",
    "out_list = np.array(out_list)\n",
    "val_loss /= len(train_loader)\n",
    "test_accuracy = correct / total\n",
    "sens_p_epoch = TP / (TP + FN) if (TP+FN != 0 ) else sens_p\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "    sens_p = TP / (TP + FN) if (TP+FN != 0 ) else sens_p\n",
    "print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {val_loss:.4f}, Train accuracy: {test_accuracy:.4f}, Sensitivity: {sens_p_epoch:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf45e686-06f3-4e31-98b1-9c87a58ee900",
   "metadata": {},
   "outputs": [],
   "source": [
    "(out_list > 0.5).sum() / len(out_list)\n",
    "seg_labels_for_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642cb960-f2ea-49f8-94b6-02030813332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = OneDCNN(6).to(device)\n",
    "# torch.save(model, 'test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d04bc37-1623-41a0-83c2-7a35f31c8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_number(model):\n",
    "    total_num = sum(p.numel() for p in model.parameters())\n",
    "    trainable_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return {'Total': total_num, 'Trainable': trainable_num}\n",
    "get_parameter_number(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8538c487-1bc0-46b3-b078-b722c61ffc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "22 * 21 * 20 / 3 /2/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be54981b-6c4e-4cc1-99d7-d034a85fe1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extract_parameters = 0\n",
    "for name, parameter in model.named_parameters():\n",
    "    print(name, parameter.numel())\n",
    "    if 'features' in name:\n",
    "        feature_extract_parameters += parameter.numel()\n",
    "print( feature_extract_parameters )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78526282-1faf-4c39-be0e-abd042e97b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_parameters = 0\n",
    "for name, parameter in model.named_parameters():\n",
    "    print(name, parameter.numel())\n",
    "    if 'classifier' in name:\n",
    "        classifier_parameters += parameter.numel()\n",
    "print( classifier_parameters )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9708eae3-5152-4a7d-bc0c-9afaca7dde36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iii in range(segments.shape[1]):\n",
    "    segments[:, iii, :] = normalize( segments[:, iii, :].squeeze(), axis=1, norm='max' )\n",
    "np.max( segments[10, 1, :] ), np.min(segments[10, 1, :]), np.mean(segments[10, 1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fb5a1c-ca68-4274-a855-afdb9454c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_labels_for_train.shape, seg_labels_for_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9205f-e583-4eca-a6ff-d997e3e576e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape, targets.unsqueeze(1).shape#, (predicted == targets).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb67f2-b551-4cf9-b593-ceadfb92667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9184642f-2fae-46ca-9832-2ddf92b98018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for inputs, targets in train_loader:\n",
    "# #     print(targets.shape)\n",
    "# #     targets = targets.flatten().to(device)\n",
    "# #     print(targets.shape)\n",
    "# #     inputs = inputs.to(device)\n",
    "# #     outputs = model(inputs)\n",
    "# #     print(\"outputs.shape =\", outputs.shape)\n",
    "# #     targets = targets.to(device)\n",
    "# #     print(targets.unsqueeze(1).shape)\n",
    "# #     break\n",
    "# model00 = OneDCNN().to(device)\n",
    "# ccc = 0\n",
    "# for inputs, targets in train_loader:\n",
    "#     inputs = inputs.to(device)\n",
    "#     print(inputs.shape)\n",
    "#     targets = targets.to(device)\n",
    "#     # print(targets.shape)\n",
    "#     outputs, feature = model(inputs)\n",
    "#     print(inputs.shape, outputs.shape, targets.shape)\n",
    "#     print(feature[0, :, :])\n",
    "\n",
    "#     ccc += 1\n",
    "#     if ccc >= 2:\n",
    "#         break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6861de47-c352-433b-97d5-c1c7e4171d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(seg_labels_for_train == 1)# / len(seg_labels_for_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ff5c93-d7a4-44a8-a2ef-e1f40976b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = segments_for_train[:, i, :].squeeze()\n",
    "# temp_nor = normalize(temp, axis=1)#(temp - temp.min(axis=1, keepdims=True)) / ( temp.max(axis=1, keepdims=True) - temp.min(axis=1, keepdims=True) )\n",
    "# temp_nor.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72d4ade-bca6-4620-91e5-e1958ecaa38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs.shape, targets.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e91e58-3135-4305-9a09-2eb2fb987079",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# orig_seg_labels[0:5], seg_labels[0:5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ed3a42-6e55-423b-be50-3baa15eb7ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(seg_labels_for_test == 1)# / seg_labels_for_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df3445-3676-43e3-a0ea-d4ae5d0749b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOTE_NUM = 5\n",
    "y_test = np.array(seg_labels_for_test)\n",
    "y_test_flat = y_test[VOTE_NUM - 1:]\n",
    "for epoch in range(50, 100):\n",
    "    start_time = time.time()\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    for interation, (inputs, targets) in enumerate(train_loader):\n",
    "        # print(interation)\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        functional.reset_net( model )\n",
    "\n",
    "        # print(outputs.shape, targets.shape)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        targets = (targets>0.5).to(device)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = correct / len(seg_labels_for_train)\n",
    "\n",
    "\n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    predictions = []\n",
    "    # targets = []\n",
    "    with torch.inference_mode():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "            predictions.extend( predicted.cpu() )\n",
    "            \n",
    "            functional.reset_net( model )\n",
    "\n",
    "        predictions = np.array( predictions )\n",
    "        final_predictions_flat = np.array( [ mode(predictions[ i-(VOTE_NUM-1) : i+1 ]).mode for i in range(VOTE_NUM-1, len(predictions)) ] )\n",
    "        \n",
    "        # 计算混淆矩阵的四个基本元素\n",
    "        TP = np.sum((predictions == 1) & (y_test == 1))  # True Positives\n",
    "        TN = np.sum((predictions == 0) & (y_test == 0))  # True Negatives\n",
    "        FP = np.sum((predictions == 1) & (y_test == 0))  # False Positives\n",
    "        FN = np.sum((predictions == 0) & (y_test == 1))  # False Negatives\n",
    "        \n",
    "        TP_vote = np.sum((final_predictions_flat == 1) & (y_test_flat == 1))  # True Positives\n",
    "        TN_vote = np.sum((final_predictions_flat == 0) & (y_test_flat == 0))  # True Negatives\n",
    "        FP_vote = np.sum((final_predictions_flat == 1) & (y_test_flat == 0))  # False Positives\n",
    "        FN_vote = np.sum((final_predictions_flat == 0) & (y_test_flat == 1))  # False Negatives\n",
    "            \n",
    "            \n",
    "        \n",
    "            # total += targets.size(0)\n",
    "            # positive_labels = ( targets == 1 )\n",
    "            # negative_labels = ( targets == 0 )\n",
    "            # correct += (predicted == targets).sum().item()\n",
    "            # TP += ( positive_labels * ( predicted == targets ) ).sum().item()\n",
    "            # FN += ( positive_labels * ( predicted != targets ) ).sum().item()\n",
    "            # TN += ( negative_labels * ( predicted == targets ) ).sum().item()\n",
    "            # FP += ( negative_labels * ( predicted != targets ) ).sum().item()\n",
    "            \n",
    "            # print( predicted.shape, targets.shape )\n",
    "            \n",
    "            \n",
    "    val_loss /= len(val_loader)\n",
    "    test_accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    sens_p_epoch = TP / (TP + FN) if (TP+FN != 0 ) else 0\n",
    "    spec_p_epoch = TN / (TN + FP) if (TN+FP != 0 ) else 0\n",
    "\n",
    "    test_acc_vote = (TP_vote + TN_vote) / (TP_vote + TN_vote + FP_vote + FN_vote)\n",
    "    sens_p_epoch_vote = TP_vote / (TP_vote + FN_vote) if (TP_vote+FN_vote != 0 ) else 0\n",
    "    spec_p_epoch_vote = TN_vote / (TN_vote + FP_vote) if (TN_vote+FP_vote != 0 ) else 0\n",
    "    \n",
    "    if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "        sens_p = TP / (TP + FN) if (TP+FN != 0 ) else 0\n",
    "        spec_p = TN / (TN + FP) if (TN+FP != 0 ) else 0\n",
    "    end_time = time.time()\n",
    "    time_cost = end_time - start_time\n",
    "    print(f'\\nEpoch [{epoch+1}/{num_epochs}], time cost: {time_cost:.4f}, Train Loss: {train_loss:.4f}, Train acc: {train_acc: .4f}, Val loss: {val_loss:.4f}, Test accuracy: {test_accuracy:.4f}, Sensitivity: {sens_p_epoch:.4f}, Specificity: {spec_p_epoch:.4f}, Test acc vote: {test_acc_vote:.4f}, Sens vote: {sens_p_epoch_vote:.4f}, Spec vote: {spec_p_epoch_vote:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "# clf = DecisionTreeClassifier(random_state=0)\n",
    "# clf.fit(segments_for_train_pca, seg_labels_for_train)\n",
    "\n",
    "# y_pred = clf.predict(segments_for_test_pca)\n",
    "\n",
    "# # seg_labels_for_test = np.array(seg_labels_for_test)\n",
    "# # true_positive = np.sum(( seg_labels_for_test == 2 ) * ( y_pred == 2 ))\n",
    "# # false_negtive = \n",
    "\n",
    "# sens_p = calculate_sensitivity_np(seg_labels_for_test, y_pred, 1)\n",
    "# # # sens_i = calculate_sensitivity_np(seg_labels_for_test, y_pred, 0)\n",
    "# sens_inter = calculate_sensitivity_np(seg_labels_for_test, y_pred, 0)\n",
    "# accuracy = calculate_accuracy_np(seg_labels_for_test, y_pred)\n",
    "print(COMMON_CH)\n",
    "# print(\"***********\\nSensitivity for pre-ictal:\", sens_p, \", sensitivity for inter:\", sens_inter)\n",
    "print(\"\\n***********\")\n",
    "print(\"Acc:\", best_test_accuracy, \"Sensitivity for pre-ictal:\", sens_p, \"Specificity:\", spec_p)\n",
    "print(\"***********\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd11fd8-3f8a-48ec-bbf8-4882692bdd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOTE_NUM = 5\n",
    "y_test = np.array(seg_labels_for_test)\n",
    "y_test_flat = y_test[VOTE_NUM - 1:]\n",
    "for epoch in range(100, 200):\n",
    "    start_time = time.time()\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    for interation, (inputs, targets) in enumerate(train_loader):\n",
    "        # print(interation)\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        functional.reset_net( model )\n",
    "\n",
    "        # print(outputs.shape, targets.shape)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        targets = (targets>0.5).to(device)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = correct / len(seg_labels_for_train)\n",
    "\n",
    "\n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    predictions = []\n",
    "    # targets = []\n",
    "    with torch.inference_mode():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "            predictions.extend( predicted.cpu() )\n",
    "            \n",
    "            functional.reset_net( model )\n",
    "\n",
    "        predictions = np.array( predictions )\n",
    "        final_predictions_flat = np.array( [ mode(predictions[ i-(VOTE_NUM-1) : i+1 ]).mode for i in range(VOTE_NUM-1, len(predictions)) ] )\n",
    "        \n",
    "        # 计算混淆矩阵的四个基本元素\n",
    "        TP = np.sum((predictions == 1) & (y_test == 1))  # True Positives\n",
    "        TN = np.sum((predictions == 0) & (y_test == 0))  # True Negatives\n",
    "        FP = np.sum((predictions == 1) & (y_test == 0))  # False Positives\n",
    "        FN = np.sum((predictions == 0) & (y_test == 1))  # False Negatives\n",
    "        \n",
    "        TP_vote = np.sum((final_predictions_flat == 1) & (y_test_flat == 1))  # True Positives\n",
    "        TN_vote = np.sum((final_predictions_flat == 0) & (y_test_flat == 0))  # True Negatives\n",
    "        FP_vote = np.sum((final_predictions_flat == 1) & (y_test_flat == 0))  # False Positives\n",
    "        FN_vote = np.sum((final_predictions_flat == 0) & (y_test_flat == 1))  # False Negatives\n",
    "            \n",
    "            \n",
    "        \n",
    "            # total += targets.size(0)\n",
    "            # positive_labels = ( targets == 1 )\n",
    "            # negative_labels = ( targets == 0 )\n",
    "            # correct += (predicted == targets).sum().item()\n",
    "            # TP += ( positive_labels * ( predicted == targets ) ).sum().item()\n",
    "            # FN += ( positive_labels * ( predicted != targets ) ).sum().item()\n",
    "            # TN += ( negative_labels * ( predicted == targets ) ).sum().item()\n",
    "            # FP += ( negative_labels * ( predicted != targets ) ).sum().item()\n",
    "            \n",
    "            # print( predicted.shape, targets.shape )\n",
    "            \n",
    "            \n",
    "    val_loss /= len(val_loader)\n",
    "    test_accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    sens_p_epoch = TP / (TP + FN) if (TP+FN != 0 ) else 0\n",
    "    spec_p_epoch = TN / (TN + FP) if (TN+FP != 0 ) else 0\n",
    "\n",
    "    test_acc_vote = (TP_vote + TN_vote) / (TP_vote + TN_vote + FP_vote + FN_vote)\n",
    "    sens_p_epoch_vote = TP_vote / (TP_vote + FN_vote) if (TP_vote+FN_vote != 0 ) else 0\n",
    "    spec_p_epoch_vote = TN_vote / (TN_vote + FP_vote) if (TN_vote+FP_vote != 0 ) else 0\n",
    "    \n",
    "    if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "        sens_p = TP / (TP + FN) if (TP+FN != 0 ) else 0\n",
    "        spec_p = TN / (TN + FP) if (TN+FP != 0 ) else 0\n",
    "    end_time = time.time()\n",
    "    time_cost = end_time - start_time\n",
    "    print(f'\\nEpoch [{epoch+1}/{num_epochs}], time cost: {time_cost:.4f}, Train Loss: {train_loss:.4f}, Train acc: {train_acc: .4f}, Val loss: {val_loss:.4f}, Test accuracy: {test_accuracy:.4f}, Sensitivity: {sens_p_epoch:.4f}, Specificity: {spec_p_epoch:.4f}, Test acc vote: {test_acc_vote:.4f}, Sens vote: {sens_p_epoch_vote:.4f}, Spec vote: {spec_p_epoch_vote:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "# clf = DecisionTreeClassifier(random_state=0)\n",
    "# clf.fit(segments_for_train_pca, seg_labels_for_train)\n",
    "\n",
    "# y_pred = clf.predict(segments_for_test_pca)\n",
    "\n",
    "# # seg_labels_for_test = np.array(seg_labels_for_test)\n",
    "# # true_positive = np.sum(( seg_labels_for_test == 2 ) * ( y_pred == 2 ))\n",
    "# # false_negtive = \n",
    "\n",
    "# sens_p = calculate_sensitivity_np(seg_labels_for_test, y_pred, 1)\n",
    "# # # sens_i = calculate_sensitivity_np(seg_labels_for_test, y_pred, 0)\n",
    "# sens_inter = calculate_sensitivity_np(seg_labels_for_test, y_pred, 0)\n",
    "# accuracy = calculate_accuracy_np(seg_labels_for_test, y_pred)\n",
    "print(COMMON_CH)\n",
    "# print(\"***********\\nSensitivity for pre-ictal:\", sens_p, \", sensitivity for inter:\", sens_inter)\n",
    "print(\"\\n***********\")\n",
    "print(\"Acc:\", best_test_accuracy, \"Sensitivity for pre-ictal:\", sens_p, \"Specificity:\", spec_p)\n",
    "print(\"***********\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c273a1ca-356c-4937-bca1-d48f072c7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOTE_NUM = 3\n",
    "y_test = np.array(seg_labels_for_test)\n",
    "y_test_flat = y_test[VOTE_NUM - 1:]\n",
    "for epoch in range(200, 210):\n",
    "    start_time = time.time()\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    for interation, (inputs, targets) in enumerate(train_loader):\n",
    "        # print(interation)\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        functional.reset_net( model )\n",
    "\n",
    "        # print(outputs.shape, targets.shape)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        targets = (targets>0.5).to(device)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = correct / len(seg_labels_for_train)\n",
    "\n",
    "\n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    predictions = []\n",
    "    # targets = []\n",
    "    with torch.inference_mode():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "            predictions.extend( predicted.cpu() )\n",
    "            \n",
    "            functional.reset_net( model )\n",
    "\n",
    "        predictions = np.array( predictions )\n",
    "        final_predictions_flat = np.array( [ mode(predictions[ i-(VOTE_NUM-1) : i+1 ]).mode for i in range(VOTE_NUM-1, len(predictions)) ] )\n",
    "        \n",
    "        # 计算混淆矩阵的四个基本元素\n",
    "        TP = np.sum((predictions == 1) & (y_test == 1))  # True Positives\n",
    "        TN = np.sum((predictions == 0) & (y_test == 0))  # True Negatives\n",
    "        FP = np.sum((predictions == 1) & (y_test == 0))  # False Positives\n",
    "        FN = np.sum((predictions == 0) & (y_test == 1))  # False Negatives\n",
    "        \n",
    "        TP_vote = np.sum((final_predictions_flat == 1) & (y_test_flat == 1))  # True Positives\n",
    "        TN_vote = np.sum((final_predictions_flat == 0) & (y_test_flat == 0))  # True Negatives\n",
    "        FP_vote = np.sum((final_predictions_flat == 1) & (y_test_flat == 0))  # False Positives\n",
    "        FN_vote = np.sum((final_predictions_flat == 0) & (y_test_flat == 1))  # False Negatives\n",
    "            \n",
    "            \n",
    "        \n",
    "            # total += targets.size(0)\n",
    "            # positive_labels = ( targets == 1 )\n",
    "            # negative_labels = ( targets == 0 )\n",
    "            # correct += (predicted == targets).sum().item()\n",
    "            # TP += ( positive_labels * ( predicted == targets ) ).sum().item()\n",
    "            # FN += ( positive_labels * ( predicted != targets ) ).sum().item()\n",
    "            # TN += ( negative_labels * ( predicted == targets ) ).sum().item()\n",
    "            # FP += ( negative_labels * ( predicted != targets ) ).sum().item()\n",
    "            \n",
    "            # print( predicted.shape, targets.shape )\n",
    "            \n",
    "            \n",
    "    val_loss /= len(val_loader)\n",
    "    test_accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    sens_p_epoch = TP / (TP + FN) if (TP+FN != 0 ) else 0\n",
    "    spec_p_epoch = TN / (TN + FP) if (TN+FP != 0 ) else 0\n",
    "\n",
    "    test_acc_vote = (TP_vote + TN_vote) / (TP_vote + TN_vote + FP_vote + FN_vote)\n",
    "    sens_p_epoch_vote = TP_vote / (TP_vote + FN_vote) if (TP_vote+FN_vote != 0 ) else 0\n",
    "    spec_p_epoch_vote = TN_vote / (TN_vote + FP_vote) if (TN_vote+FP_vote != 0 ) else 0\n",
    "    \n",
    "    if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "        sens_p = TP / (TP + FN) if (TP+FN != 0 ) else 0\n",
    "        spec_p = TN / (TN + FP) if (TN+FP != 0 ) else 0\n",
    "    end_time = time.time()\n",
    "    time_cost = end_time - start_time\n",
    "    print(f'\\nEpoch [{epoch+1}/{num_epochs}], time cost: {time_cost:.4f}, Train Loss: {train_loss:.4f}, Train acc: {train_acc: .4f}, Val loss: {val_loss:.4f}, Test accuracy: {test_accuracy:.4f}, Sensitivity: {sens_p_epoch:.4f}, Specificity: {spec_p_epoch:.4f}, Test acc vote: {test_acc_vote:.4f}, Sens vote: {sens_p_epoch_vote:.4f}, Spec vote: {spec_p_epoch_vote:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "# clf = DecisionTreeClassifier(random_state=0)\n",
    "# clf.fit(segments_for_train_pca, seg_labels_for_train)\n",
    "\n",
    "# y_pred = clf.predict(segments_for_test_pca)\n",
    "\n",
    "# # seg_labels_for_test = np.array(seg_labels_for_test)\n",
    "# # true_positive = np.sum(( seg_labels_for_test == 2 ) * ( y_pred == 2 ))\n",
    "# # false_negtive = \n",
    "\n",
    "# sens_p = calculate_sensitivity_np(seg_labels_for_test, y_pred, 1)\n",
    "# # # sens_i = calculate_sensitivity_np(seg_labels_for_test, y_pred, 0)\n",
    "# sens_inter = calculate_sensitivity_np(seg_labels_for_test, y_pred, 0)\n",
    "# accuracy = calculate_accuracy_np(seg_labels_for_test, y_pred)\n",
    "print(COMMON_CH)\n",
    "# print(\"***********\\nSensitivity for pre-ictal:\", sens_p, \", sensitivity for inter:\", sens_inter)\n",
    "print(\"\\n***********\")\n",
    "print(\"Acc:\", best_test_accuracy, \"Sensitivity for pre-ictal:\", sens_p, \"Specificity:\", spec_p)\n",
    "print(\"***********\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54393110-3043-40bc-898d-96d4fe35af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n***********\")\n",
    "print(\"Acc:\", best_test_accuracy, \"Sensitivity for pre-ictal:\", sens_p, \"Specificity:\", spec_p)\n",
    "print(\"***********\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58905fc7-4e1f-4043-93d1-1e52e3642ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a33aa3-3584-4b0b-b846-89ab8c904885",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, PATIENT_TO_USE+str(epoch)+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528cd160-0f43-4b8c-bce1-060b02eebc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## torch.save(model.state_dict(), str(epoch)+'_state_dict.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_EEG",
   "language": "python",
   "name": "eeg_seizure"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
